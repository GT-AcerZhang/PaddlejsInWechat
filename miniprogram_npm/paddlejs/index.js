!function(t,e){"object"==typeof exports&&"object"==typeof module?module.exports=e():"function"==typeof define&&define.amd?define([],e):"object"==typeof exports?exports.panorama=e():t.panorama=e()}(window,(function(){return function(t){var e={};function n(i){if(e[i])return e[i].exports;var r=e[i]={i:i,l:!1,exports:{}};return t[i].call(r.exports,r,r.exports,n),r.l=!0,r.exports}return n.m=t,n.c=e,n.d=function(t,e,i){n.o(t,e)||Object.defineProperty(t,e,{enumerable:!0,get:i})},n.r=function(t){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(t,"__esModule",{value:!0})},n.t=function(t,e){if(1&e&&(t=n(t)),8&e)return t;if(4&e&&"object"==typeof t&&t&&t.__esModule)return t;var i=Object.create(null);if(n.r(i),Object.defineProperty(i,"default",{enumerable:!0,value:t}),2&e&&"string"!=typeof t)for(var r in t)n.d(i,r,function(e){return t[e]}.bind(null,r));return i},n.n=function(t){var e=t&&t.__esModule?function(){return t.default}:function(){return t};return n.d(e,"a",e),e},n.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)},n.p="",n(n.s=10)}([function(t,e,n){t.exports=n(11)},function(t,e){t.exports=function(t,e){if(!(t instanceof e))throw new TypeError("Cannot call a class as a function")}},function(t,e){function n(t,e){for(var n=0;n<e.length;n++){var i=e[n];i.enumerable=i.enumerable||!1,i.configurable=!0,"value"in i&&(i.writable=!0),Object.defineProperty(t,i.key,i)}}t.exports=function(t,e,i){return e&&n(t.prototype,e),i&&n(t,i),t}},function(t,e,n){var i=n(12),r=n(13),o=n(14),a=n(16);t.exports=function(t,e){return i(t)||r(t,e)||o(t,e)||a()}},function(t,e){function n(t,e,n,i,r,o,a){try{var s=t[o](a),u=s.value}catch(t){return void n(t)}s.done?e(u):Promise.resolve(u).then(i,r)}t.exports=function(t){return function(){var e=this,i=arguments;return new Promise((function(r,o){var a=t.apply(e,i);function s(t){n(a,r,o,s,u,"next",t)}function u(t){n(a,r,o,s,u,"throw",t)}s(void 0)}))}}},function(t,e){function n(e){return t.exports=n=Object.setPrototypeOf?Object.getPrototypeOf:function(t){return t.__proto__||Object.getPrototypeOf(t)},n(e)}t.exports=n},function(t,e,n){var i=n(17);t.exports=function(t,e){if("function"!=typeof e&&null!==e)throw new TypeError("Super expression must either be null or a function");t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,writable:!0,configurable:!0}}),e&&i(t,e)}},function(t,e,n){var i=n(18),r=n(19);t.exports=function(t,e){return!e||"object"!==i(e)&&"function"!=typeof e?r(t):e}},function(t,e){t.exports=function(t){throw new Error('"'+t+'" is read-only')}},function(t,e){t.exports=function(t,e,n){return e in t?Object.defineProperty(t,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):t[e]=n,t}},function(t,e,n){t.exports=n(21)},function(t,e,n){var i=function(t){"use strict";var e=Object.prototype,n=e.hasOwnProperty,i="function"==typeof Symbol?Symbol:{},r=i.iterator||"@@iterator",o=i.asyncIterator||"@@asyncIterator",a=i.toStringTag||"@@toStringTag";function s(t,e,n,i){var r=e&&e.prototype instanceof h?e:h,o=Object.create(r.prototype),a=new v(i||[]);return o._invoke=function(t,e,n){var i="suspendedStart";return function(r,o){if("executing"===i)throw new Error("Generator is already running");if("completed"===i){if("throw"===r)throw o;return R()}for(n.method=r,n.arg=o;;){var a=n.delegate;if(a){var s=g(a,n);if(s){if(s===_)continue;return s}}if("next"===n.method)n.sent=n._sent=n.arg;else if("throw"===n.method){if("suspendedStart"===i)throw i="completed",n.arg;n.dispatchException(n.arg)}else"return"===n.method&&n.abrupt("return",n.arg);i="executing";var h=u(t,e,n);if("normal"===h.type){if(i=n.done?"completed":"suspendedYield",h.arg===_)continue;return{value:h.arg,done:n.done}}"throw"===h.type&&(i="completed",n.method="throw",n.arg=h.arg)}}}(t,n,a),o}function u(t,e,n){try{return{type:"normal",arg:t.call(e,n)}}catch(t){return{type:"throw",arg:t}}}t.wrap=s;var _={};function h(){}function l(){}function c(){}var f={};f[r]=function(){return this};var T=Object.getPrototypeOf,p=T&&T(T(H([])));p&&p!==e&&n.call(p,r)&&(f=p);var E=c.prototype=h.prototype=Object.create(f);function d(t){["next","throw","return"].forEach((function(e){t[e]=function(t){return this._invoke(e,t)}}))}function I(t,e){var i;this._invoke=function(r,o){function a(){return new e((function(i,a){!function i(r,o,a,s){var _=u(t[r],t,o);if("throw"!==_.type){var h=_.arg,l=h.value;return l&&"object"==typeof l&&n.call(l,"__await")?e.resolve(l.__await).then((function(t){i("next",t,a,s)}),(function(t){i("throw",t,a,s)})):e.resolve(l).then((function(t){h.value=t,a(h)}),(function(t){return i("throw",t,a,s)}))}s(_.arg)}(r,o,i,a)}))}return i=i?i.then(a,a):a()}}function g(t,e){var n=t.iterator[e.method];if(void 0===n){if(e.delegate=null,"throw"===e.method){if(t.iterator.return&&(e.method="return",e.arg=void 0,g(t,e),"throw"===e.method))return _;e.method="throw",e.arg=new TypeError("The iterator does not provide a 'throw' method")}return _}var i=u(n,t.iterator,e.arg);if("throw"===i.type)return e.method="throw",e.arg=i.arg,e.delegate=null,_;var r=i.arg;return r?r.done?(e[t.resultName]=r.value,e.next=t.nextLoc,"return"!==e.method&&(e.method="next",e.arg=void 0),e.delegate=null,_):r:(e.method="throw",e.arg=new TypeError("iterator result is not an object"),e.delegate=null,_)}function m(t){var e={tryLoc:t[0]};1 in t&&(e.catchLoc=t[1]),2 in t&&(e.finallyLoc=t[2],e.afterLoc=t[3]),this.tryEntries.push(e)}function x(t){var e=t.completion||{};e.type="normal",delete e.arg,t.completion=e}function v(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(m,this),this.reset(!0)}function H(t){if(t){var e=t[r];if(e)return e.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var i=-1,o=function e(){for(;++i<t.length;)if(n.call(t,i))return e.value=t[i],e.done=!1,e;return e.value=void 0,e.done=!0,e};return o.next=o}}return{next:R}}function R(){return{value:void 0,done:!0}}return l.prototype=E.constructor=c,c.constructor=l,c[a]=l.displayName="GeneratorFunction",t.isGeneratorFunction=function(t){var e="function"==typeof t&&t.constructor;return!!e&&(e===l||"GeneratorFunction"===(e.displayName||e.name))},t.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,a in t||(t[a]="GeneratorFunction")),t.prototype=Object.create(E),t},t.awrap=function(t){return{__await:t}},d(I.prototype),I.prototype[o]=function(){return this},t.AsyncIterator=I,t.async=function(e,n,i,r,o){void 0===o&&(o=Promise);var a=new I(s(e,n,i,r),o);return t.isGeneratorFunction(n)?a:a.next().then((function(t){return t.done?t.value:a.next()}))},d(E),E[a]="Generator",E[r]=function(){return this},E.toString=function(){return"[object Generator]"},t.keys=function(t){var e=[];for(var n in t)e.push(n);return e.reverse(),function n(){for(;e.length;){var i=e.pop();if(i in t)return n.value=i,n.done=!1,n}return n.done=!0,n}},t.values=H,v.prototype={constructor:v,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=void 0,this.done=!1,this.delegate=null,this.method="next",this.arg=void 0,this.tryEntries.forEach(x),!t)for(var e in this)"t"===e.charAt(0)&&n.call(this,e)&&!isNaN(+e.slice(1))&&(this[e]=void 0)},stop:function(){this.done=!0;var t=this.tryEntries[0].completion;if("throw"===t.type)throw t.arg;return this.rval},dispatchException:function(t){if(this.done)throw t;var e=this;function i(n,i){return a.type="throw",a.arg=t,e.next=n,i&&(e.method="next",e.arg=void 0),!!i}for(var r=this.tryEntries.length-1;r>=0;--r){var o=this.tryEntries[r],a=o.completion;if("root"===o.tryLoc)return i("end");if(o.tryLoc<=this.prev){var s=n.call(o,"catchLoc"),u=n.call(o,"finallyLoc");if(s&&u){if(this.prev<o.catchLoc)return i(o.catchLoc,!0);if(this.prev<o.finallyLoc)return i(o.finallyLoc)}else if(s){if(this.prev<o.catchLoc)return i(o.catchLoc,!0)}else{if(!u)throw new Error("try statement without catch or finally");if(this.prev<o.finallyLoc)return i(o.finallyLoc)}}}},abrupt:function(t,e){for(var i=this.tryEntries.length-1;i>=0;--i){var r=this.tryEntries[i];if(r.tryLoc<=this.prev&&n.call(r,"finallyLoc")&&this.prev<r.finallyLoc){var o=r;break}}o&&("break"===t||"continue"===t)&&o.tryLoc<=e&&e<=o.finallyLoc&&(o=null);var a=o?o.completion:{};return a.type=t,a.arg=e,o?(this.method="next",this.next=o.finallyLoc,_):this.complete(a)},complete:function(t,e){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&e&&(this.next=e),_},finish:function(t){for(var e=this.tryEntries.length-1;e>=0;--e){var n=this.tryEntries[e];if(n.finallyLoc===t)return this.complete(n.completion,n.afterLoc),x(n),_}},catch:function(t){for(var e=this.tryEntries.length-1;e>=0;--e){var n=this.tryEntries[e];if(n.tryLoc===t){var i=n.completion;if("throw"===i.type){var r=i.arg;x(n)}return r}}throw new Error("illegal catch attempt")},delegateYield:function(t,e,n){return this.delegate={iterator:H(t),resultName:e,nextLoc:n},"next"===this.method&&(this.arg=void 0),_}},t}(t.exports);try{regeneratorRuntime=i}catch(t){Function("r","regeneratorRuntime = r")(i)}},function(t,e){t.exports=function(t){if(Array.isArray(t))return t}},function(t,e){t.exports=function(t,e){if("undefined"!=typeof Symbol&&Symbol.iterator in Object(t)){var n=[],i=!0,r=!1,o=void 0;try{for(var a,s=t[Symbol.iterator]();!(i=(a=s.next()).done)&&(n.push(a.value),!e||n.length!==e);i=!0);}catch(t){r=!0,o=t}finally{try{i||null==s.return||s.return()}finally{if(r)throw o}}return n}}},function(t,e,n){var i=n(15);t.exports=function(t,e){if(t){if("string"==typeof t)return i(t,e);var n=Object.prototype.toString.call(t).slice(8,-1);return"Object"===n&&t.constructor&&(n=t.constructor.name),"Map"===n||"Set"===n?Array.from(t):"Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)?i(t,e):void 0}}},function(t,e){t.exports=function(t,e){(null==e||e>t.length)&&(e=t.length);for(var n=0,i=new Array(e);n<e;n++)i[n]=t[n];return i}},function(t,e){t.exports=function(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}},function(t,e){function n(e,i){return t.exports=n=Object.setPrototypeOf||function(t,e){return t.__proto__=e,t},n(e,i)}t.exports=n},function(t,e){function n(e){return"function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?t.exports=n=function(t){return typeof t}:t.exports=n=function(t){return t&&"function"==typeof Symbol&&t.constructor===Symbol&&t!==Symbol.prototype?"symbol":typeof t},n(e)}t.exports=n},function(t,e){t.exports=function(t){if(void 0===t)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return t}},function(t,e){t.exports=function(t,e,n,i){var r=new Blob(void 0!==i?[i,t]:[t],{type:n||"application/octet-stream"});if(void 0!==window.navigator.msSaveBlob)window.navigator.msSaveBlob(r,e);else{var o=window.URL&&window.URL.createObjectURL?window.URL.createObjectURL(r):window.webkitURL.createObjectURL(r),a=document.createElement("a");a.style.display="none",a.href=o,a.setAttribute("download",e),void 0===a.download&&a.setAttribute("target","_blank"),document.body.appendChild(a),a.click(),setTimeout((function(){document.body.removeChild(a),window.URL.revokeObjectURL(o)}),200)}}},function(t,e,n){"use strict";n.r(e);var i=n(1),r=n.n(i),o=n(2),a=n.n(o),s=function(){function t(){r()(this,t),this.ENV={}}return a()(t,null,[{key:"setEntry",value:function(t,e){this.ENV[t]=e}},{key:"env",value:function(){return this.ENV||(this.ENV=new t),this.ENV}}]),t}(),u=n(0),_=n.n(u),h=n(4),l=n.n(h),c=n(3),f=n.n(c),T=n(9),p=n.n(T);function E(t,e){var n=Object.keys(t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(t);e&&(i=i.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),n.push.apply(n,i)}return n}function d(t){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?E(Object(n),!0).forEach((function(e){p()(t,e,n[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(n)):E(Object(n)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(n,e))}))}return t}var I=function(){function t(){r()(this,t);var e=!s.env().canvas;this.fromPixels2DContext=e&&document.createElement("canvas").getContext("2d"),this.fromPixels2DContext2=e&&document.createElement("canvas").getContext("2d"),this.defaultWidth=224,this.defaultHeight=224,this.minPixels=225,this.pixels="",this.defaultParams={gapFillWith:"#000",mean:[0,0,0],std:[1,1,1]}}return a()(t,[{key:"process",value:function(t){var e=t.input,n=(t.mode,t.channel,t.rotate,d(d({},this.defaultParams),t.params));if(!this.result){var i=f()(n.targetShape,4),r=(i[0],i[1]),o=i[2],a=i[3];this.result=new Float32Array(o*a*r)}return this.fromPixels(e,n)}},{key:"reshape",value:function(t,e,n){for(var i=n.sw,r=n.sh,o=e.width,a=e.height,s=Math.ceil((i-o)/2),u=Math.ceil((r-a)/2),_=t.data,h=[],l=[],c=[],f=e.mean,T=e.std,p=0;p<_.length;p+=4){var E=p/4,d=Math.floor(E/i),I=E-d*i-1;I>=s&&I<s+o&&d>=u&&d<u+a&&(h.push((_[p]/255-f[0])/T[0]),l.push((_[p+1]/255-f[1])/T[1]),c.push((_[p+2]/255-f[2])/T[2]))}var g=l.concat(c);return h.concat(g)}},{key:"allReshapeToRGB",value:function(t,e){var n=e.mean,i=e.std,r=e.normalizeType,o=void 0===r?0:r,a=e.targetShape,s=f()(a,4),u=(s[0],s[1]),_=s[2],h=s[3],l=t.data||t,c=this.result,T=0;if(!c){var p=f()(a,4),E=(p[0],p[1]),d=p[2],I=p[3];c=new Float32Array(d*I*E)}for(var g=0;g<_;++g)for(var m=g*h,x=0;x<h;++x)for(var v=m+x,H=0;H<u;++H){var R=4*v+H;c[T]=0===o?l[R]/255:(l[R]-128)/128,c[T]-=n[H],c[T]/=i[H],T++}return c}},{key:"allReshapeToBGR",value:function(t,e,n){for(var i=f()(e.targetShape,4),r=(i[0],i[1]),o=i[2],a=i[3],s=t.data||t,u=e.mean,_=e.std,h=(s.length,this.result),l=0,c=0;c<o;++c)for(var T=c*a,p=0;p<a;++p)for(var E=T+p,d=0;d<r;++d){var I=4*E+(2-d);h[l]=s[I],h[l]-=u[2-d],h[l]/=_[2-d],l++}return h}},{key:"reSize",value:function(t,e){var n=this.pixelWidth,i=this.pixelHeight,r=n,o=i;return n<i?(r=e.scale||n,o=Math.round(r*i/n)):n>i?(o=e.scale||i,r=Math.round(o*n/i)):r=o=e.scale||n,this.fromPixels2DContext.canvas.width=r,this.fromPixels2DContext.canvas.height=o,this.fromPixels2DContext.drawImage(t,0,0,r,o),this.setInputCanvas(t),{sw:r,sh:o}}},{key:"resizeAndFitTargetSize",value:function(t,e){var n=this.pixelWidth,i=this.pixelHeight,r=n,o=i;n<i?(r=e.scale,o=Math.round(r*i/n)):(o=e.scale,r=Math.round(o*n/i)),this.fromPixels2DContext.canvas.width=r,this.fromPixels2DContext.canvas.height=o;var a=e.targetSize.width,s=e.targetSize.height;this.fromPixels2DContext.drawImage(t,0,0,r,o);var u=(r-a)/2,_=(o-s)/2;r=a,o=s;var h=this.getImageData(e,u,_,{sw:r,sh:o});return this.setInputCanvas(t),h}},{key:"fitToTargetSize",value:function(t,e,n){var i=e.targetSize.width,r=e.targetSize.height;this.fromPixels2DContext.canvas.width=i,this.fromPixels2DContext.canvas.height=r,this.fromPixels2DContext.fillStyle=e.gapFillWith,this.fromPixels2DContext.fillRect(0,0,r,i);var o=i,a=r,s=0,u=0;return i/r*this.pixelHeight/this.pixelWidth>=1?(o=Math.round(a*this.pixelWidth/this.pixelHeight),s=Math.floor((i-o)/2)):(a=Math.round(o*this.pixelHeight/this.pixelWidth),u=Math.floor((r-a)/2)),n?this.fromPixels2DContext.drawImage(t,s,u,o,a):this.fromPixels2DContext.drawImage(t,0,0,o,a),this.setInputCanvas(t),{sw:i,sh:r}}},{key:"setInputCanvas",value:function(t){var e=this.pixelWidth,n=this.pixelHeight;this.fromPixels2DContext2.canvas.width=e,this.fromPixels2DContext2.canvas.height=n,this.fromPixels2DContext2.drawImage(t,0,0,e,n)}},{key:"getImageData",value:function(t,e,n,i){var r=i.sw,o=i.sh;return this.fromPixels2DContext.getImageData(e,n,r,o)}},{key:"grayscale",value:function(t){for(var e=t.data,n=0;n<e.length;n+=4){var i=(e[n]+e[n+1]+e[n+2])/3;e[n]=i,e[n+1]=i,e[n+2]=i}return e}},{key:"fromPixels",value:function(t,e){var n,i,r;return(t instanceof HTMLImageElement||t instanceof HTMLVideoElement)&&(this.pixelWidth=t.naturalWidth||t.videoWidth||t.width,this.pixelHeight=t.naturalHeight||t.videoWidth||t.height,e.scale&&e.targetSize?(n=this.resizeAndFitTargetSize(t,e),i=this.fromPixels2DContext2.getImageData(0,0,this.pixelWidth,this.pixelHeight)):e.targetSize?(r=this.fitToTargetSize(t,e),n=this.getImageData(e,0,0,r),i=this.fromPixels2DContext2.getImageData(0,0,this.pixelWidth,this.pixelHeight)):(r=this.reSize(t,e),n=this.getImageData(e,0,0,r),i=this.fromPixels2DContext2.getImageData(0,0,this.pixelWidth,this.pixelHeight))),e.gray&&(n=grayscale(n)),e.reShape&&(n=this.reshape(n,e,r)),e.bgr?n=this.allReshapeToBGR(n,e,r):e.targetShape&&(n=this.allReshapeToRGB(n,e,r)),[{data:n,shape:e.shape||e.targetShape,name:"image",canvas:i}]}}]),t}(),g=function(){function t(e,n){r()(this,t),this.version="0.0.1",this.data={},this.modelGonfig=e,this.options=n,this.multipart=!1,this.test=!1,this.chunkNum=0,this.params={type:"fetch"},this.fetch=s.env().fetch||this.fetchFunc,this.options&&(this.multipart=this.options.multipart,"binary"===n.dataType&&(this.binaryOption=n.options,this.dataType=n.dataType),n.test&&(this.test=!0)),this.loadOptions||(this.loadOptions={})}var e,n;return a()(t,[{key:"fetchOneChunk",value:function(t){return this.fetch(t,{type:"arrayBuffer"})}},{key:"fetchJson",value:function(t){return this.fetch(t,{type:"json"})}},{key:"fetchChunks",value:function(){for(var t=this,e=this.chunkNum||this.binaryOption.fileCount,n=[],i=1;i<=e;i++)n.push(this.fetchOneChunk(this.modelGonfig.dir+this.binaryOption.getFileName(i)));return Promise.all(n).then((function(e){var n,i=0,r=[];e.forEach((function(t){n=new Float32Array(t),r.push(n),i+=n.length})),t.allData=new Float32Array(i);var o=0;r.forEach((function(e){e.forEach((function(e){t.allData[o]=e,o+=1}))}))}))}},{key:"fetchData",value:function(t){var e=this.modelGonfig.dir+t+".json";return new Promise((function(t,n){fetchJson(e,{method:"get",mode:"cors",credentials:"include",headers:{"Content-Type":"application/json;charset=utf-8"}}).then((function(e){return t(e)})).then((function(t){return n(t)}))}))}},{key:"fetchAllDate",value:(n=l()(_.a.mark((function t(e){var n,i=this;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return n=e.map((function(t){return t.name?i.fetchData(t.name).then((function(e){return t.data=e})):Promise.resolve()})),t.abrupt("return",Promise.all(n));case 4:case"end":return t.stop()}}),t)}))),function(t){return n.apply(this,arguments)})},{key:"traverse",value:function(t){var e,n=this,i=0;t.filter((function(t){return t.name})).forEach((function(t){e=t.shape.reduce((function(t,e){return t*e})),t.persistable&&(t.data=n.allData.slice(i,i+e),i+=e)}))}},{key:"fetchFunc",value:function(t,e){var n=e=e||this.params,i=n.method,r=void 0===i?"get":i,o=(n.mode,n.type),a=new Headers,s=fetch(t,{method:r,headers:a});switch(o){case"json":return s.then((function(t){return t.json()}));case"arrayBuffer":return s.then((function(t){return t.arrayBuffer()}));default:return s}}},{key:"fetchModel",value:function(t){var e=this;t=t||this.params;var n=this.modelGonfig.dir+this.modelGonfig.main,i=null;if(t&&"jsonp"===t.type){var r,o=document.createElement("script");o.src=n+"&jsonpCallback=fn",window.fn=function(t){r=t},document.body.appendChild(o),i=new Promise((function(t,e){o.onload=function(e){t(r)},o.onerror=function(){e(r)}})),this.data=i}else"fetch"===t.type?(i=new Promise((function(i,r){e.fetchJson(n,t).then((function(t){return i(t)})).then((function(t){return r(t)}))})),this.data=i):"xhr"===t.type&&(this.data=i);return i}},{key:"load",value:(e=l()(_.a.mark((function t(){var e,n,i=this;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return e=this,t.next=3,this.fetchModel();case 3:if(n=this.data=t.sent,this.chunkNum=n.chunkNum,!0!==this.multipart){t.next=13;break}if("binary"!==this.dataType){t.next=11;break}return t.next=9,this.fetchChunks().then((function(){return i.traverse(n.vars)}));case 9:t.next=13;break;case 11:return t.next=13,e.fetchAllDate(n.vars);case 13:return t.abrupt("return",n);case 14:case"end":return t.stop()}}),t,this)}))),function(){return e.apply(this,arguments)})}]),t}(),m=function(){function t(e){r()(this,t),this.inputs=e.inputs,this.outputs=e.outputs,this.attrs=e.attrs||e["sub-attrs"],this.type=e.type,this.finish=!1,this.next=null,this.opData=null,this.id=+new Date+e.type+Math.floor(10*Math.random()+1)+e.idx}return a()(t,[{key:"execute",value:function(t,e){"feed"!==this.type?t.run(this.type,this.opData,e):+Date.now()}},{key:"inputsName",get:function(){return"feed"===this.type||"batchnorm"===this.type||"batch_norm"===this.type?this.inputs.X:"conv2d"===this.type||"depthwise_conv2d"===this.type||"conv2d_transpose"===this.type?this.inputs.Input:"elementwise_add"===this.type||"concat"===this.type?this.inputs.X.concat(this.inputs.Y):"relu"===this.type||"leaky_relu"===this.type||"pool2d"===this.type||"mul"===this.type||"softmax"===this.type||"scale"===this.type||"fetch"===this.type?this.inputs.X:this.inputs.Input||this.inputs.X}},{key:"outputsName",get:function(){return this.outputs.Output?this.outputs.Output:this.outputs.out?this.outputs.out:"conv2d"===this.type||"depthwise_conv2d"===this.type?this.outputs.Output:"batchnorm"===this.type||"batch_norm"===this.type?(this.outputs.out=this.outputs.Y,delete this.outputs.Y,this.outputs.out):this.outputs.Y?(this.outpus.out=this.outputs.Y,this.outputs.out):this.outputs.Out||this.outputs.Output}}]),t}(),x={alpha:!1,antialias:!1,premultipliedAlpha:!1,preserveDrawingBuffer:!1,depth:!1,stencil:!1,failIfMajorPerformanceCaveat:!0},v=function(){function t(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};r()(this,t),this.version=2,this.opts=e,this.frameBufferSupportFloat=!0,e.width_raw_canvas=Number(e.width_raw_canvas)||512,e.height_raw_canvas=Number(e.height_raw_canvas)||512;var n=null;if(this.opts.gl)n=this.opts.gl,this.version=1,this.internalFormat=n.RGBA,this.textureFormat=n.RGBA,this.downloadInternalFormat=n.RGBA,this.textureFloat=n.getExtension("OES_texture_float"),this.textureHalfFloat=n.getExtension("OES_texture_half_float"),this.frameBufferSupportFloat=this.isDownloadFloatTextureEnabled(n);else{var i=s.env().canvas||e.el||document.createElement("canvas");!s.env().canvas&&i.addEventListener("webglcontextlost",(function(t){t.preventDefault(),console.log("webgl context is lost~")}),!1),(n=i.getContext("webgl2",x))?(this.version=2,this.textureFloat=n.getExtension("EXT_color_buffer_float"),this.internalFormat=n.R16F,this.textureFormat=n.RED,this.downloadInternalFormat=n.RGBA16F):(n=i.getContext("webgl",x)||i.getContext("experimental-webgl",x),this.version=1,this.internalFormat=n.RGBA,this.textureFormat=n.RGBA,this.downloadInternalFormat=n.RGBA,n?(this.textureFloat=n.getExtension("OES_texture_float"),this.textureHalfFloat=n.getExtension("OES_texture_half_float"),this.frameBufferSupportFloat=this.isDownloadFloatTextureEnabled(n)):(this.version=0,alert("当前环境创建webgl context失败")))}this.maxTextureSize=n.getParameter(n.MAX_TEXTURE_SIZE),this.maxTextureImageUnits=n.getParameter(n.MAX_TEXTURE_IMAGE_UNITS),n.disable(n.DEPTH_TEST),n.disable(n.STENCIL_TEST),n.disable(n.BLEND),n.disable(n.DITHER),n.disable(n.POLYGON_OFFSET_FILL),n.disable(n.SAMPLE_COVERAGE),n.enable(n.SCISSOR_TEST),n.enable(n.CULL_FACE),n.cullFace(n.BACK),this.gl=n,this.initCache(),this.waits=0}return a()(t,[{key:"getWebglVersion",value:function(){return this.version}},{key:"getWebglMaxTextureSize",value:function(){return this.maxTextureSize}},{key:"getWebglMaxTextureImageUnits",value:function(){return this.maxTextureImageUnits}},{key:"getIsFrameBufferSupportFloat",value:function(){return this.frameBufferSupportFloat}},{key:"initCache",value:function(){this.times=0;var t=this.gl,e=new Float32Array([-1,1,0,1,-1,-1,0,0,1,1,1,1,1,-1,1,0]);this.vertexBuffer=t.createBuffer(),t.bindBuffer(t.ARRAY_BUFFER,this.vertexBuffer),t.bufferData(t.ARRAY_BUFFER,e,t.STATIC_DRAW),this.vertexShader=null,this.initShader(2===this.version?"#version 300 es\nin vec4 position;\nout vec2 vCoord;\n\nvoid main() {\n    vCoord.x = (position.x + 1.0) / 2.0;\n    vCoord.y = (position.y + 1.0) / 2.0;\n    gl_Position = position;\n}\n":"\nprecision highp float;\nprecision highp int;\n\nattribute vec4 position;\nvarying vec2 vCoord;\n\nvoid main() {\n    vCoord.x = (position.x + 1.0) / 2.0;\n    vCoord.y = (position.y + 1.0) / 2.0;\n    gl_Position = position;\n}\n"),this.fragmentShader=null,this.prevTexture=null,this.currentTexture=null,this.frameBuffer=t.createFramebuffer(),t.bindFramebuffer(t.FRAMEBUFFER,this.frameBuffer),this.cacheTextures={},this.uniformLocations={},this.texturesMap={},this.pbo=t.createBuffer()}},{key:"runVertexShader",value:function(t){var e=this.gl,n=e.getAttribLocation(t,"position");e.enableVertexAttribArray(n),e.bindBuffer(e.ARRAY_BUFFER,this.vertexBuffer),e.vertexAttribPointer(n,2,e.FLOAT,!1,16,0)}},{key:"setOutProps",value:function(t){this.width_shape_out=t.width_shape||1,this.height_shape_out=t.height_shape||1,this.width_texture_out=t.width_texture||1,this.height_texture_out=t.height_texture||1,this.channel=t.channel||0,this.total_shape=t.total_shape||0}},{key:"isFloatingTexture",value:function(){return null!==this.textureFloat}},{key:"isDownloadFloatTextureEnabled",value:function(t){var e=t.createTexture();t.bindTexture(t.TEXTURE_2D,e);t.texImage2D(t.TEXTURE_2D,0,this.downloadInternalFormat,1,1,0,t.RGBA,t.FLOAT,null);var n=t.createFramebuffer();t.bindFramebuffer(t.FRAMEBUFFER,n),t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,e,0);var i=t.checkFramebufferStatus(t.FRAMEBUFFER)===t.FRAMEBUFFER_COMPLETE;return t.bindTexture(t.TEXTURE_2D,null),t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteTexture(e),t.deleteFramebuffer(n),i}},{key:"createProgram",value:function(t,e){var n=this.gl,i=n.createProgram();n.attachShader(i,this.vertexShader),n.attachShader(i,t),n.linkProgram(i);var r=n.createTexture();return n.bindTexture(n.TEXTURE_2D,r),n.texParameteri(n.TEXTURE_2D,n.TEXTURE_MAG_FILTER,n.NEAREST),n.texParameteri(n.TEXTURE_2D,n.TEXTURE_MIN_FILTER,n.NEAREST),n.texParameteri(n.TEXTURE_2D,n.TEXTURE_WRAP_S,n.CLAMP_TO_EDGE),n.texParameteri(n.TEXTURE_2D,n.TEXTURE_WRAP_T,n.CLAMP_TO_EDGE),n.texImage2D(n.TEXTURE_2D,0,this.downloadInternalFormat,e.width_texture,e.height_texture,0,n.RGBA,this.frameBufferSupportFloat?n.FLOAT:this.textureHalfFloat.HALF_FLOAT_OES,null),n.bindTexture(n.TEXTURE_2D,null),this.texturesMap[e.tensorId]=r,i}},{key:"setProgram",value:function(t,e){this.gl.useProgram(t),this.program=t,e||this.runVertexShader(t)}},{key:"attachShader",value:function(t){var e=this.gl,n=this.program;this.textureBufferIndex=this.textureBufferIndex+1>=2?0:1,this.fragmentShader&&e.detachShader(n,this.fragmentShader),this.gl.attachShader(n,t),this.fragmentShader=t,e.linkProgram(n),0==this.times++&&(e.useProgram(n),this.runVertexShader())}},{key:"create",value:function(t,e){var n=this.gl;this.program&&this.dispose();var i=this.program=n.createProgram();this.initShader(t),this.fragmentShader=this.initShader(e,"fragment"),this.gl.attachShader(i,this.vertexShader),this.gl.attachShader(i,this.fragmentShader),n.linkProgram(i),n.useProgram(i);var r=n.getAttribLocation(i,"position");n.enableVertexAttribArray(r),n.bindBuffer(n.ARRAY_BUFFER,this.vertexBuffer),n.vertexAttribPointer(r,2,n.FLOAT,!1,16,0)}},{key:"initShader",value:function(t){var e,n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"vertex",i="vertex"===n?this.gl.VERTEX_SHADER:this.gl.FRAGMENT_SHADER;if("vertex"===n&&this.vertexShader)e=this.vertexShader;else if(e=this.gl.createShader(i),"vertex"===n&&(this.vertexShader=e),this.gl.shaderSource(e,t),this.gl.compileShader(e),!this.gl.getShaderParameter(e,this.gl.COMPILE_STATUS))throw new Error("compile: "+this.gl.getShaderInfoLog(e));return e}},{key:"updateShader",value:function(t){return this.gl.useProgram(this.program),this.fragmentShader&&(this.gl.detachShader(this.program,this.fragmentShader),this.gl.deleteShader(this.fragmentShader),this.gl.deleteTexture(this.texture)),this.fragmentShader=this.initShader(t,"fragment"),!0}},{key:"attachFrameBuffer",value:function(t,e){this.prevTexture=this.currentTexture,this.currentTexture=this.texturesMap[e];var n=this.gl;return n.framebufferTexture2D(n.FRAMEBUFFER,n.COLOR_ATTACHMENT0,n.TEXTURE_2D,this.currentTexture,0),n.viewport(0,0,this.width_texture_out,this.height_texture_out),n.scissor(0,0,this.width_texture_out,this.height_texture_out),this.frameBuffer}},{key:"frameBufferIsComplete",value:function(){var t,e,n,i=this.gl;switch(e=i.checkFramebufferStatus(i.FRAMEBUFFER)){case i.FRAMEBUFFER_COMPLETE:t="Framebuffer is complete.",n=!0;break;case i.FRAMEBUFFER_UNSUPPORTED:t="Framebuffer is unsupported",n=!1;break;case i.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:t="Framebuffer incomplete attachment",n=!1;break;case i.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:t="Framebuffer incomplete (missmatched) dimensions",n=!1;break;case i.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:t="Framebuffer incomplete missing attachment",n=!1;break;default:t="Unexpected framebuffer status: "+e,n=!1}return{isComplete:n,message:t}}},{key:"initTexture",value:function(t,e,n,i){var r,o=this.gl;if(0===n&&"feed"===e.tensorId&&this.opts&&this.opts.usePipeLine)r=this.texturesMap.image,e.data=null;else if(e.data){if(i&&(n>0||0===n&&"origin"!==e.tensor))r=this.cacheTextures[""+n][e.variable+"_"+e.tensor];else r=o.createTexture(),this.cacheTextures[""+n]=this.cacheTextures[""+n]||{},this.cacheTextures[""+n][e.variable+"_"+e.tensor]=r}else r=this.texturesMap[e.tensorId];if(o.activeTexture(o["TEXTURE".concat(t)]),o.bindTexture(o.TEXTURE_2D,r),e.data&&(!i||i&&0===n&&"origin"===e.tensor))if(o.texParameteri(o.TEXTURE_2D,o.TEXTURE_MAG_FILTER,o.NEAREST),o.texParameteri(o.TEXTURE_2D,o.TEXTURE_MIN_FILTER,o.NEAREST),o.texParameteri(o.TEXTURE_2D,o.TEXTURE_WRAP_S,o.CLAMP_TO_EDGE),o.texParameteri(o.TEXTURE_2D,o.TEXTURE_WRAP_T,o.CLAMP_TO_EDGE),2==this.version)o.texImage2D(o.TEXTURE_2D,0,this.internalFormat,e.width_texture,e.height_texture,0,this.textureFormat,o.FLOAT,e.data);else{e.width_texture,e.height_texture;for(var a=new Float32Array(e.width_texture*e.height_texture*4),s=0;s<e.data.length;s++)a[4*s]=e.data[s],a[4*s+1]=0,a[4*s+2]=0,a[4*s+3]=0;o.texImage2D(o.TEXTURE_2D,0,o.RGBA,e.width_texture,e.height_texture,0,o.RGBA,o.FLOAT,a)}}},{key:"getUniformLoc",value:function(t,e,n){if(n)return this.uniformLocations[""+e][t];var i=this.gl.getUniformLocation(this.program,t);return this.uniformLocations[""+e]=this.uniformLocations[""+e]||{},this.uniformLocations[""+e][t]=i,i}},{key:"makeTexure",value:function(t,e){var n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},i=this.gl,r=int(mod(float(this.textureBufferIndex),2)),o=this.textureBuffer[r];return i.bindTexture(i.TEXTURE_2D,o),i.texImage2D(i.TEXTURE_2D,0,i.RGBA,n.width_texture_out||this.width_texture_out,n.height_texture_out||this.height_texture_out,0,i.RGBA,t,e),this.attachFrameBuffer(),o}},{key:"render",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,n=arguments.length>2&&void 0!==arguments[2]&&arguments[2],i=this.gl,r=this,o=0;t.forEach((function(t){if("texture"===t.type){var a=r.getUniformLoc(t.variable+"_"+t.tensor,e,n);if(!a)return;r.initTexture(o,t,e,n),i.uniform1i(a,o++)}else"uniform"===t.type&&i[t.setter](r.getUniformLoc(t.variable+"_"+t.tensor,e,n),t.data)})),i.drawArrays(i.TRIANGLE_STRIP,0,4)}},{key:"createPBO",value:function(){if(2==this.version){var t=this.gl,e=this.pbo;t.bindBuffer(t.PIXEL_PACK_BUFFER,e);var n=16*this.width_texture_out*this.height_texture_out;return t.bufferData(t.PIXEL_PACK_BUFFER,n,t.STREAM_READ),t.readPixels(0,0,this.width_texture_out,this.height_texture_out,t.RGBA,t.FLOAT,0),t.bindBuffer(t.PIXEL_PACK_BUFFER,null),e}var i=new Float32Array(this.width_texture_out*this.height_texture_out*4),r=this.gl;return r.readPixels(0,0,this.width_texture_out,this.height_texture_out,r.RGBA,r.FLOAT,i),i}},{key:"downloadFoat32TensorFromBuffer",value:function(t){var e=this.gl,n=4*this.width_texture_out*this.height_texture_out;if(2==this.version){var i=new Float32Array(n);e.bindBuffer(e.PIXEL_PACK_BUFFER,t),e.getBufferSubData(e.PIXEL_PACK_BUFFER,0,i),e.bindBuffer(e.PIXEL_PACK_BUFFER,null);for(var r=[],o=0;o<this.width_texture_out*this.height_texture_out;o++)r.push(i[4*o]);return r}for(var a=t,s=[],u=0;u<this.width_texture_out*this.height_texture_out;u++)s.push(a[4*u]);return s}},{key:"getWebglError",value:function(t){var e=this.gl;switch(t){case e.NO_ERROR:return"NO_ERROR";case e.INVALID_ENUM:return"INVALID_ENUM";case e.INVALID_VALUE:return"INVALID_VALUE";case e.INVALID_OPERATION:return"INVALID_OPERATION";case e.INVALID_FRAMEBUFFER_OPERATION:return"INVALID_FRAMEBUFFER_OPERATION";case e.OUT_OF_MEMORY:return"OUT_OF_MEMORY";case e.CONTEXT_LOST_WEBGL:return"CONTEXT_LOST_WEBGL";default:return"Unknown error code ".concat(t)}}},{key:"createAndWaitForFence",value:function(){var t=this,e=this.gl,n=null!=e.fenceSync,i=function(){return!0};if(n){var r=e.fenceSync(e.SYNC_GPU_COMMANDS_COMPLETE,0);e.flush(),i=function(){var t=e.clientWaitSync(r,0,0);return t===e.ALREADY_SIGNALED||t===e.CONDITION_SATISFIED}}return new Promise((function(e){t.pollItem(i,e)}))}},{key:"pollItem",value:function(t,e){!function n(){t()?e():setTimeout(n,1)}()}},{key:"compute",value:function(){var t=this.gl,e=(Date.now(),new Float32Array(this.width_texture_out*this.height_texture_out*4));Date.now();t.readPixels(0,0,this.width_texture_out,this.height_texture_out,t.RGBA,t.FLOAT,e);for(var n=[],i=0;i<this.width_texture_out*this.height_texture_out;i++)n.push(e[4*i]);return n}},{key:"dispose",value:function(){var t=this,e=this.gl;this.cacheTextures={},this.programs.forEach((function(n){e.detachShader(n,t.vertexShader),e.deleteShader(t.vertexShader),e.deleteProgram(n)})),this.programs=[]}}]),t}(),H="\n    // 输入数据\n    uniform sampler2D texture_origin;\n",R="\n// start函数\nvoid main(void) {\n    // 输出数据\n    float o = getPixelsFromTexturePos_texture_origin(vCoord).r;\n    float res = ACTIVE_FUNCTION(o, multi_value, bias_value);\n    setOutput(res);\n}\n",N={dep:[{func:"getPixelsFromTexturePos",conf:{TEXTURE_NAME:"texture_origin"}}],conf:["WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","FUSE_RELU","MULTI_VALUE","BIAS_VALUE","ACTIVE_FUNCTION"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]},P={common:{params:"\n    // dynamic的input数据\n    const float multi_value = float(MULTI_VALUE);\n    const float bias_value = float(BIAS_VALUE);\n    const bool fuse_relu =  bool(FUSE_RELU);\n\n    // 输出数据\n    const int width_shape_out = WIDTH_SHAPE_OUT;\n    const int height_shape_out = HEIGHT_SHAPE_OUT;\n    const int width_texture_out = WIDTH_TEXTURE_OUT;\n    const int height_texture_out = HEIGHT_TEXTURE_OUT;\n    const int channel_out = CHANNEL_OUT;\n    const int offset_y_out = OFFSET_Y_OUT;\n",func:"\n// 激活函数\nfloat prelu(float x, float p, float b) {\n    float result = x;\n    if (x < 0.0) {\n        result = x * p;\n    }\n    \n    return result;\n}\nfloat relu6(float x, float threshold, float b) {\n        float result = max(0.0,x);\n        result = min(result,threshold);\n        return result;\n}\nfloat leakyRelu(float x, float p, float b) {\n    float result = max(x, x * p);\n    return result;\n}\n\nfloat scale(float x, float p, float b) {\n    float result = p * x + b;\n    return result;\n}\n\nfloat sigmoid(float x, float y, float z) {\n    float result = 1.0 / (1.0 + exp(-x));\n    return result;\n}\n\nfloat softmax(float x, float p, float b) {\n    float result = exp(x) / (10.0 * exp(x));\n    return result;\n}\n\n",prefix:"\n#ifdef GL_FRAGMENT_PRECISION_HIGH\n    precision highp float;\n    precision highp int;\n#else\n    precision highp float;\n    precision highp int;\n#endif\n    varying vec2 vCoord;\n    varying vec4 outColor;\n    void setOutput(float result) {\n            gl_FragColor.r = result;\n    }\n",prefixHalf:"\n#ifdef GL_FRAGMENT_PRECISION_HIGH\n    precision highp float;\n    precision highp int;\n#else\n    precision highp float;\n    precision highp int;\n#endif\n\n    #define isnan(value) isnan_custom(value)\n    bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n    }\n\n    varying vec2 vCoord;\n    varying vec4 outColor;\n    void setOutput(float result) {\n        if(isnan(result)) {\n            gl_FragColor.r = 0.0;\n        }else {\n            gl_FragColor.r = result;\n        }\n    }\n",prefix2:"#version 300 es\n\n#ifdef GL_FRAGMENT_PRECISION_HIGH\n    precision highp float;\n    precision highp int;\n#else\n    precision mediump float;\n    precision mediump int;\n#endif\n\n// 顶点shader透传的材质坐标\n    in vec2 vCoord;\n    out vec4 outColor;\n    void setOutput(float result) {\n        outColor.r = result;\n    }\n",suffix:"\nvec2 _2d_shape_texture_out = vec2(float(width_texture_out), float(height_texture_out));\nivec4 getOutputTensorPos() {\n    // 获取原始长度\n    vec2 outCoord = vCoord.xy * _2d_shape_texture_out;\n    int x = int(outCoord.x / float(channel_out));\n    int c = int(mod(outCoord.x, float(channel_out)));\n    int y = int(mod(outCoord.y, float(height_shape_out)));\n    int b = int(outCoord.y / float(height_shape_out));\n    return ivec4(b, c, y, x);\n}\n\n\nivec4 getOutputTensorPosLimit() {\n    // 获取原始长度\n    vec2 outCoord = vCoord.xy * _2d_shape_texture_out;\n    float offsetY = floor(outCoord.y / float(height_shape_out));\n    int x = int(outCoord.x / float(channel_out));\n    if (mod(offsetY, 4.0) > 0.0) {\n        x += int(mod(offsetY, 4.0)) * int(ceil(float(width_shape_out) / 4.0));\n    }\n    int y = int(mod(outCoord.y, float(height_shape_out)));\n    int c = int(mod(outCoord.x, float(channel_out)));\n    int b = int(outCoord.y / float(4 * height_shape_out));\n    return ivec4(b, c, y, x);\n}\n\nivec4 getOutputPackedTensorPos() {\n    // 获取原始长度\n    vec2 outCoord = vCoord.xy * _2d_shape_texture_out;\n    int height = height_shape_out + offset_y_out;\n    int x = int(outCoord.x);\n    int c = int(outCoord.y / float(height / 2));\n    int y = int(mod(outCoord.y, float(height / 2)));\n    int b = 0;\n    return ivec4(b, c, y, x);\n}\n",ivec56:"\nstruct ivec5 {\n    int x;\n    int y;\n    int z;\n    int w;\n    int u;\n};\nstruct ivec6 {\n    int x;\n    int y;\n    int z;\n    int w;\n    int u;\n    int v;\n};\n"},ops:{conv2d_transpose:{params:"\n    // conv2d的input数据\n\n    // 常量\n    // 卷积核\n    const int length_shape_filter = LENGTH_SHAPE_FILTER;\n    const int width_shape_filter = WIDTH_SHAPE_FILTER;\n    const int height_shape_filter = HEIGHT_SHAPE_FILTER;\n    const int width_texture_filter = WIDTH_TEXTURE_FILTER;\n    const int height_texture_filter = HEIGHT_TEXTURE_FILTER;\n    const int channel_filter = CHANNEL_FILTER;\n\n    // 输入数据\n    const int width_shape_origin = WIDTH_SHAPE_ORIGIN;\n    const int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\n    const int length_shape_origin = LENGTH_SHAPE_ORIGIN;\n    const int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\n    const int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\n    const int channel_origin = CHANNEL_ORIGIN;\n\n    // 计算相关\n    // 拆分步长\n    const int stride_h = int(STRIDES_X);\n    const int stride_v = int(STRIDES_Y);\n    // padding的数目\n    const int padLeft = WIDTH_SHAPE_FILTER - PADDINGS_X - 1;\n    const int padTop = HEIGHT_SHAPE_FILTER - PADDINGS_Y - 1;\n\n    // dilation膨胀系数\n    const int dilation_h = DILATIONS_X;\n    const int dilation_v = DILATIONS_Y;\n    // groups\n    const int groups = GROUPS;\n\n    // uniform变量\n    // 卷积核\n    uniform sampler2D texture_filter;\n\n    // 输入数据\n    uniform sampler2D texture_origin;\n",func:"\n    // start函数\n    void main(void) {\n        ivec4 oPos = getOutputTensorPosLIMIT_OUT();\n        int x = oPos.a;\n        int c = oPos.g;\n        int y = oPos.b;\n        int b = oPos.r;\n        float res = 0.0;\n        int temp_x = 0;\n        int temp_y = 0;\n        float o = 0.0;\n        float f = 0.0;\n        \n        // 获取output的坐标\n        int oTensorChannel = int(c * groups / channel_out) * channel_origin;\n        int oy = y - padTop;\n        for (int fy = 0; fy < height_shape_filter; fy++) {\n            if (oy < 0) {\n                oy += dilation_v;\n                continue;\n            }\n            int ox = x - padLeft;\n            for (int fx = 0; fx < width_shape_filter; fx++) {\n\n                if (ox < 0) {\n                    ox += dilation_h;\n                    continue;\n                }\n                // channel计算\n                for (int j = 0; j < channel_origin; j++) {\n                \tif (int(mod(float(ox), float(stride_h))) == 0 && int(mod(float(oy), float(stride_v))) == 0) {\n\t\t\t\t\t\ttemp_x = int(floor(float(ox) / float(stride_h)));\n\t\t\t\t\t\ttemp_y = int(floor(float(oy) / float(stride_v)));\n                        if (temp_x < width_shape_origin && temp_y < height_shape_origin){\n\t\t\t\t\t\t    o = getValueFromTensorPosLIMIT_ORIGIN_origin(b, j, temp_y, temp_x);\n                            f = getValueFromTensorPosLIMIT_FILTER_filter(j, c, height_shape_filter-1-fy, width_shape_filter-1-fx);\n                            res += f * o;\n                        }\n\t\t\t\t\t}\n                }\n                ox += dilation_h;\n            }\n            oy += dilation_v;\n        }\n        setOutput(float(res));\n    }\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"filter"}}],conf:["LENGTH_SHAPE_FILTER","WIDTH_SHAPE_FILTER","HEIGHT_SHAPE_FILTER","WIDTH_TEXTURE_FILTER","HEIGHT_TEXTURE_FILTER","CHANNEL_FILTER","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","STRIDE_HORIZONTAL","STRIDE_VERTICAL","PAD_LEFT","PAD_TOP","DILATION_HORIZONTAL","DILATION_VERTICAL","GROUPS","MULTI_VALUE","BIAS_VALUE","ACTIVE_FUNCTION"],input:[{tensor:"filter",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},conv2d:{params:"\n    // conv2d的input数据\n\n    // 常量\n    // 卷积核\n    const int length_shape_filter = LENGTH_SHAPE_FILTER;\n    const int width_shape_filter = WIDTH_SHAPE_FILTER;\n    const int height_shape_filter = HEIGHT_SHAPE_FILTER;\n    const int width_texture_filter = WIDTH_TEXTURE_FILTER;\n    const int height_texture_filter = HEIGHT_TEXTURE_FILTER;\n    const int channel_filter = CHANNEL_FILTER;\n\n    // 输入数据\n    const int width_shape_origin = WIDTH_SHAPE_ORIGIN;\n    const int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\n    const int length_shape_origin = LENGTH_SHAPE_ORIGIN;\n    const int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\n    const int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\n    const int channel_origin = CHANNEL_ORIGIN;\n\n    // bias\n    const int width_shape_bias = WIDTH_SHAPE_BIAS;\n    const int height_shape_bias = HEIGHT_SHAPE_BIAS;\n    const int length_shape_bias = LENGTH_SHAPE_BIAS;\n    const int width_texture_bias = WIDTH_TEXTURE_BIAS;\n    const int height_texture_bias = HEIGHT_TEXTURE_BIAS;\n    const int channel_bias = CHANNEL_BIAS;\n\n    // 计算相关\n    // 拆分步长\n    const int stride_h = STRIDES_X;\n    const int stride_v = STRIDES_Y;\n    // padding的数目\n    const int padLeft = PADDINGS_X;\n    const int padTop = PADDINGS_Y;\n    // dilation膨胀系数\n    const int dilation_h = DILATIONS_X;\n    const int dilation_v = DILATIONS_Y;\n    // groups\n    const int groups = GROUPS;\n\n    // uniform变量\n    // 卷积核\n    uniform sampler2D texture_filter;\n\n    // 输入数据\n    uniform sampler2D texture_origin;\n\n\n    // bias\n    uniform sampler2D texture_bias;\n",func:"\n    // start函数\n    void main(void) {\n        ivec4 oPos = getOutputTensorPosLIMIT_OUT();\n        int x = oPos.a;\n        int c = oPos.g;\n        int y = oPos.b;\n        int b = oPos.r;\n        float res = 0.0;\n\n        // 获取output的坐标\n        int oTensorChannel = (c / (channel_out / groups)) * channel_filter;\n        int oy = y * stride_v - padTop;\n        for (int fy = 0; fy < height_shape_filter; fy++) {\n            if (oy >= height_shape_origin) {\n                break;\n            }\n            if (oy < 0) {\n                oy += dilation_v;\n                continue;\n            }\n            int ox = x * stride_h - padLeft;\n            for (int fx = 0; fx < width_shape_filter; fx++) {\n                if (ox >= width_shape_origin) {\n                    break;\n                }\n                if (ox < 0) {\n                    ox += dilation_h;\n                    continue;\n                }\n                // channel计算\n                for (int j = 0; j < channel_filter; j++) {\n                    float f = getValueFromTensorPosLIMIT_FILTER_filter(c, j, fy, fx);\n                    float o = getValueFromTensorPosLIMIT_ORIGIN_origin(b, oTensorChannel + j, oy, ox);\n                    res += f * o;\n                }\n                ox += dilation_h;\n            }\n            oy += dilation_v;\n        }\n\n        float bi = getValueFromTensorPosLIMIT_BIAS_bias(0, 0, 0, c);\n        res += bi;\n        if (fuse_relu) {\n            res = max(0.0, res);\n        }\n        setOutput(res);\n    }\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"filter"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"bias"}},{func:"transferFromNHWCtoNCHW",conf:{}}],conf:["LENGTH_SHAPE_FILTER","WIDTH_SHAPE_FILTER","HEIGHT_SHAPE_FILTER","WIDTH_TEXTURE_FILTER","HEIGHT_TEXTURE_FILTER","CHANNEL_FILTER","WIDTH_SHAPE_BIAS","HEIGHT_SHAPE_BIAS","LENGTH_SHAPE_BIAS","WIDTH_TEXTURE_BIAS","HEIGHT_TEXTURE_BIAS","CHANNEL_BIAS","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","STRIDE_HORIZONTAL","STRIDE_VERTICAL","PAD_LEFT","PAD_TOP","DILATION_HORIZONTAL","DILATION_VERTICAL","GROUPS","MULTI_VALUE","BIAS_VALUE","FUSE_RELU","ACTIVE_FUNCTION"],input:[{tensor:"filter",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"bias",variable:"texture",setter:"initTexture",type:"texture"}]}},conv2d_depthwise:{params:"\n    // conv2d的input数据\n\n    // 常量\n    // 卷积核\n    const int length_shape_filter = LENGTH_SHAPE_FILTER;\n    const int width_shape_filter = WIDTH_SHAPE_FILTER;\n    const int height_shape_filter = HEIGHT_SHAPE_FILTER;\n    const int width_texture_filter = WIDTH_TEXTURE_FILTER;\n    const int height_texture_filter = HEIGHT_TEXTURE_FILTER;\n    const int channel_filter = CHANNEL_FILTER;\n\n    // 输入数据\n    const int width_shape_origin = WIDTH_SHAPE_ORIGIN;\n    const int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\n    const int length_shape_origin = LENGTH_SHAPE_ORIGIN;\n    const int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\n    const int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\n    const int channel_origin = CHANNEL_ORIGIN;\n\n    // bias\n    const int width_shape_bias = WIDTH_SHAPE_BIAS;\n    const int height_shape_bias = HEIGHT_SHAPE_BIAS;\n    const int length_shape_bias = LENGTH_SHAPE_BIAS;\n    const int width_texture_bias = WIDTH_TEXTURE_BIAS;\n    const int height_texture_bias = HEIGHT_TEXTURE_BIAS;\n    const int channel_bias = CHANNEL_BIAS;\n\n    // 计算相关\n    // 拆分步长\n    const int stride_h = STRIDES_X;\n    const int stride_v = STRIDES_Y;\n    // padding的数目\n    const int padLeft = PADDINGS_X;\n    const int padTop = PADDINGS_Y;\n    // dilation膨胀系数\n    const int dilation_h = DILATIONS_X;\n    const int dilation_v = DILATIONS_Y;\n\n    // uniform变量\n    // 卷积核\n    uniform sampler2D texture_filter;\n\n    // 输入数据\n    uniform sampler2D texture_origin;\n\n    // bias\n    uniform sampler2D texture_bias;\n",func:"\n    // start函数\n    void main(void) {\n        ivec4 oPos = getOutputTensorPosLIMIT_OUT();\n        int x = oPos.a;\n        int c = oPos.g;\n        int y = oPos.b;\n        int b = oPos.r;\n        float res = 0.0;\n        int top = y * stride_v - padTop;\n        int left = x * stride_h - padLeft;\n        for (int fy = 0; fy < height_shape_filter; fy++) {\n          int oy = top + fy * dilation_v;\n          if (oy >= height_shape_origin) {\n              break;\n          }\n          if (oy < 0) {\n            continue;\n          }\n          for (int fx = 0; fx < width_shape_filter; fx++) {\n            int ox = left + fx * dilation_h;\n            if (ox >= width_shape_origin) {\n                break;\n            }\n            if (ox < 0) {\n                continue;\n            }\n            // b默认是0\n            float f = getValueFromTensorPosLIMIT_FILTER_filter(c, 0, fy, fx);\n            float o = getValueFromTensorPosLIMIT_ORIGIN_origin(b, c, oy, ox);\n            res += f * o;\n          }\n        }\n        float bi = getValueFromTensorPosLIMIT_BIAS_bias(0, 0, 0, c);\n        res += bi;\n        if (fuse_relu) {\n            res = max(0.0, res);\n        }\n        setOutput(res);\n    }\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"filter"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"bias"}},{func:"transferFromNHWCtoNCHW",conf:{}}],conf:["LENGTH_SHAPE_FILTER","WIDTH_SHAPE_FILTER","HEIGHT_SHAPE_FILTER","WIDTH_TEXTURE_FILTER","HEIGHT_TEXTURE_FILTER","CHANNEL_FILTER","WIDTH_SHAPE_BIAS","HEIGHT_SHAPE_BIAS","LENGTH_SHAPE_BIAS","WIDTH_TEXTURE_BIAS","HEIGHT_TEXTURE_BIAS","CHANNEL_BIAS","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","STRIDE_HORIZONTAL","STRIDE_VERTICAL","PAD_LEFT","PAD_TOP","DILATION_HORIZONTAL","DILATION_VERTICAL","MULTI_VALUE","BIAS_VALUE","ACTIVE_FUNCTION"],input:[{tensor:"filter",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"bias",variable:"texture",setter:"initTexture",type:"texture"}]}},conv2d_elementwise_add:{params:"\n    // 卷积核\n    const int length_shape_filter = LENGTH_SHAPE_FILTER;\n    const int width_shape_filter = WIDTH_SHAPE_FILTER;\n    const int height_shape_filter = HEIGHT_SHAPE_FILTER;\n    const int width_texture_filter = WIDTH_TEXTURE_FILTER;\n    const int height_texture_filter = HEIGHT_TEXTURE_FILTER;\n    const int channel_filter = CHANNEL_FILTER;\n    \n    // 输入数据\n    const int width_shape_origin = WIDTH_SHAPE_ORIGIN;\n    const int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\n    const int length_shape_origin = LENGTH_SHAPE_ORIGIN;\n    const int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\n    const int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\n    const int channel_origin = CHANNEL_ORIGIN;\n    \n    // 计算相关\n    // 拆分步长\n    const int stride_h = STRIDES_X;\n    const int stride_v = STRIDES_Y;\n    // padding的数目\n    const int padLeft = PADDINGS_X;\n    const int padTop = PADDINGS_Y;\n    // dilation膨胀系数\n    const int dilation_h = DILATIONS_X;\n    const int dilation_v = DILATIONS_Y;\n    // groups\n    const int groups = GROUPS;\n\n   const int total_shape_out = TOTAL_SHAPE_OUT;\n    // 加法\n    const int axis = AXIS;\n     \n    // uniform变量\n    // 卷积核\n    uniform sampler2D texture_filter;\n    \n    // 输入数据\n    uniform sampler2D texture_origin;\n    \n    // 加法\n    uniform sampler2D texture_counter;\n    // 加法用到的函数\n    float getValueFromCounter(int index) {\n        float xPos = float(index) / float(WIDTH_SHAPE_COUNTER);\n        vec4 pixels = TEXTURE2D(texture_counter, vec2(xPos, 0.5));\n        return pixels.r;\n    }\n",func:"\n    // start函数\n    void main(void) {\n        ivec4 oPos = getOutputTensorPosLIMIT_OUT();\n\t\t//int sumVal = oPos.g + oPos.a * channel_out + oPos.b * channel_out * width_shape_out;\n        //ivec4 new_oPos = transferFromNHWCtoNCHW(sumVal, channel_out, width_shape_out, height_shape_out, total_shape_out);\n        int x = oPos.a;\n        int c = oPos.g;\n        int y = oPos.b;\n        int b = oPos.r;\n        int addAxis = oPos[axis];\n        float res = getValueFromCounter(addAxis);\n\n        // 获取output的坐标\n        int oTensorChannel = (c / (channel_out / groups)) * channel_filter;\n        int oy = y * stride_v - padTop;\n        for (int fy = 0; fy < height_shape_filter; fy++) {\n            if (oy >= height_shape_origin) {\n                break;\n            }\n            if (oy < 0) {\n                oy += dilation_v;\n                continue;\n            }\n            int ox = x * stride_h - padLeft;\n            for (int fx = 0; fx < width_shape_filter; fx++) {\n                if (ox >= width_shape_origin) {\n                    break;\n                }\n                if (ox < 0) {\n                    ox += dilation_h;\n                    continue;\n                }\n                // channel计算\n                for (int j = 0; j < channel_filter; j++) {\n                    float f = getValueFromTensorPosLIMIT_FILTER_filter(c, j, fy, fx);\n                    float o = getValueFromTensorPosLIMIT_ORIGIN_origin(b, oTensorChannel + j, oy, ox);\n                    res += f * o;\n                }\n                ox += dilation_h;\n            }\n            oy += dilation_v;\n        }\n        setOutput(ACTIVE_FUNCTION(res, multi_value, bias_value));\n        // outColor.r = float(b);\n        // outColor.g = float(c);\n        // outColor.b = float(y);\n        // outColor.a = float(x);\n    }\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"filter"}},{func:"transferFromNHWCtoNCHW",conf:{}}],conf:["LENGTH_SHAPE_FILTER","WIDTH_SHAPE_FILTER","HEIGHT_SHAPE_FILTER","WIDTH_TEXTURE_FILTER","HEIGHT_TEXTURE_FILTER","CHANNEL_FILTER","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","WIDTH_SHAPE_COUNTER","STRIDE_HORIZONTAL","STRIDE_VERTICAL","PAD_LEFT","PAD_TOP","DILATION_HORIZONTAL","DILATION_VERTICAL","GROUPS","AXIS","MULTI_VALUE","BIAS_VALUE","ACTIVE_FUNCTION"],input:[{tensor:"filter",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"counter",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},conv2d_elementwise_add_winograd:{params:"\n    // 卷积核\n    const int length_shape_filter = LENGTH_SHAPE_FILTER;\n    const int width_shape_filter = WIDTH_SHAPE_FILTER;\n    const int height_shape_filter = HEIGHT_SHAPE_FILTER;\n    const int width_texture_filter = WIDTH_TEXTURE_FILTER;\n    const int height_texture_filter = HEIGHT_TEXTURE_FILTER;\n    const int channel_filter = CHANNEL_FILTER;\n\n    // 输入数据\n    const int width_shape_origin = WIDTH_SHAPE_ORIGIN;\n    const int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\n    const int length_shape_origin = LENGTH_SHAPE_ORIGIN;\n    const int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\n    const int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\n    const int channel_origin = CHANNEL_ORIGIN;\n    \n    // 计算相关\n    // padding的数目\n    const int padLeft = PADDINGS_X;\n    const int padTop = PADDINGS_Y;\n   \n    // 加法\n    const int axis = AXIS;\n    uniform float data_counter[TOTAL_SHAPE_COUNTER];\n     \n    // uniform变量\n    // 卷积核\n    uniform sampler2D texture_filter;\n    \n    // 输入数据\n    uniform sampler2D texture_origin;\n    // 加法用到的函数\n    float getValueFromCounter(int index) {\n        for (int i = 0; i < TOTAL_SHAPE_COUNTER; i++) {\n            if (i == index) {\n                return data_counter[i];\n            }\n        }\n        return 0.0;\n    }\n",func:"\n    // start函数\n    void main(void) {\n        ivec4 oPos = getOutputPackedTensorPos();\n        int x = oPos.a;\n        int c = oPos.g;\n        int y = oPos.b;\n        int b = oPos.r;\n        // b = 0;\n        // c = 1;\n        // y = 0;\n        // x = 0;\n        int addAxis = oPos[axis];\n        float res = getValueFromCounter(addAxis);\n        // 输出结果\n        vec4 v4 = vec4(res);\n\n        float I[16];\n        float B[16];\n        float T[16];\n        float f[16];\n        for (int cl = 0; cl < channel_filter; cl++) {\n            // 获取output的坐标\n            int oy = 2*y - padTop;\n            // 计算输入 4 * 4矩阵 和filter\n            for (int fy = 0; fy < 4; fy++) {\n                int ox = 2*x - padLeft;\n                int index = fy * 4;\n                for (int fx = 0; fx < 4; fx++) {\n                    if (oy < 0 || oy >= height_shape_origin || ox >= width_shape_origin || ox < 0) {\n                        I[index + fx] = 0.0;\n                    } else {\n                        I[index + fx] = getValueFromTensorPos_origin(b, cl, oy, ox);\n                    }\n                    f[index + fx] = getValueFromTensorPos_filter(c, cl, fy, fx);\n                    ox += 1;\n                }\n                oy += 1;\n            }\n            // input转化\n            float tmp1 = I[2] - I[10];\n            float tmp2 = I[9] - I[1];\n            B[0] = I[0] - I[8] - tmp1;\n            B[1] = tmp1 - tmp2;\n            B[2] = tmp1 + tmp2;\n            B[3] = I[3] - I[11] + tmp2;\n            tmp1 = I[6] + I[10];\n            tmp2 = I[5] + I[9];\n            B[4] = I[4] + I[8] - tmp1;\n            B[5] = tmp1 + tmp2;\n            B[6] = tmp1 - tmp2;\n            B[7] = I[7] + I[11] - tmp2;\n            tmp1 = I[10] - I[6];\n            tmp2 = I[5] - I[9];\n            B[8] = I[8] - I[4] - tmp1;\n            B[9] = tmp1 - tmp2;\n            B[10] = tmp1 + tmp2;\n            B[11] = tmp2 - I[7] + I[11];\n            tmp1 = I[14] - I[6];\n            tmp2 = I[5] - I[13];\n            B[12] = I[12] - I[4] - tmp1;\n            B[13] = tmp1 - tmp2;\n            B[14] = tmp1 + tmp2;\n            B[15] = tmp2 - I[7] + I[15];\n            // 点乘\n            for (int i = 0; i < 16; i++) {\n                T[i] = B[i] * f[i];\n            }\n            // final output\n            tmp1 = T[1] + T[5] + T[9];\n            tmp2 = T[2] + T[6] + T[10];\n            v4[0] += T[0] + T[4] + T[8] + tmp1 + tmp2;\n            v4[1] += T[3] + T[7] + T[11] + tmp1 - tmp2;\n            tmp1 = T[5] - T[9] + T[13];\n            tmp2 = T[6] - T[10] + T[14];\n            v4[2] += T[4] - T[8] + T[12] + tmp1 + tmp2;\n            v4[3] += T[7] - T[11] + T[15] + tmp1 - tmp2;\n        }\n        outColor.r = ACTIVE_FUNCTION(v4[0], multi_value, bias_value);\n        outColor.g = ACTIVE_FUNCTION(v4[1], multi_value, bias_value);\n        outColor.b = ACTIVE_FUNCTION(v4[2], multi_value, bias_value);\n        outColor.a = ACTIVE_FUNCTION(v4[3], multi_value, bias_value);\n        // outColor = v4;\n        // outColor.r = I[0];\n        // outColor.g = I[1];\n        // outColor.b = I[2];\n        // outColor.a = I[3];\n        // outColor.r = float(b);\n        // outColor.g = float(c);\n        // outColor.b = float(y);\n        // outColor.a = float(x);\n    }\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"filter"}}],conf:["LENGTH_SHAPE_FILTER","WIDTH_SHAPE_FILTER","HEIGHT_SHAPE_FILTER","WIDTH_TEXTURE_FILTER","HEIGHT_TEXTURE_FILTER","CHANNEL_FILTER","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","TOTAL_SHAPE_COUNTER","PAD_LEFT","PAD_TOP","AXIS","MULTI_VALUE","BIAS_VALUE","ACTIVE_FUNCTION"],input:[{tensor:"filter",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"counter",variable:"data",setter:"uniform1fv",type:"uniform"}]}},dynamic:{params:H,func:R,confs:N},pool2d:{params:"\n// 常量\n// 池化大小\nconst int width_shape_pool = KSIZE_X;\nconst int height_shape_pool = KSIZE_Y;\nconst int type_pool = TYPE_POOL;\n// 输入数据\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\n\n// 计算相关\n// 拆分步长\nconst int stride_h = STRIDES_X;\nconst int stride_v = STRIDES_Y;\n// padding的数目\nconst int padLeft = PADDINGS_X;\nconst int padTop = PADDINGS_Y;\n\n\n// uniform变量\nuniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n\tfloat res = 0.0;\n    // 获取output的坐标\n    ivec4 out_pos = getOutputTensorPosLIMIT_OUT();\n    // X、Y方向的移动步长\n    int count_pool = 0;\n    int oy_base = out_pos[2] * stride_v - padTop;\n    int ox_base = out_pos[3] * stride_h - padLeft;\n    for (int fy = 0; fy < height_shape_pool; fy++) {\n        int oy = oy_base + fy;\n        if (oy >= height_shape_origin) {\n            break;\n        }\n        if (oy < 0) {\n            continue;\n        }\n        for (int fx = 0; fx < width_shape_pool; fx++) {\n            int ox = ox_base + fx;\n            if (ox >= width_shape_origin) {\n                break;\n            }\n            if (ox < 0) {\n                continue;\n            }\n            // origin数据\n            float curr = getValueFromTensorPosLIMIT_ORIGIN_origin(out_pos[0], out_pos[1], oy, ox);\n            if (type_pool == 1) {\n                if (curr > res) {\n                    res = curr;\n                }\n            } else {\n                res += curr;\n                // 在平均池化模式忽略填充值(exclusive默认为true）\n                count_pool++;\n            }\n        }\n    }\n    if (type_pool != 1) {\n        res = res / float(count_pool);\n    }\n    setOutput(res);\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}}],conf:["KSIZE_X","KSIZE_Y","TYPE_POOL","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","STRIDES_X","STRIDES_Y","PADDING_X","PADDING_Y"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},pool2d_max:{params:"\n// 常量\n// 池化大小\nconst int width_shape_pool = KSIZE_X;\nconst int height_shape_pool = KSIZE_Y;\n// 输入数据\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\n\n// 计算相关\n// 拆分步长\nconst int stride_h = STRIDES_X;\nconst int stride_v = STRIDES_Y;\n// padding的数目\nconst int padLeft = PADDINGS_X;\nconst int padTop = PADDINGS_Y;\n\n\n// uniform变量\nuniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    float res = 0.0;\n    // 获取output的坐标\n    ivec4 out_pos = getOutputTensorPosLIMIT_OUT();\n    int b = out_pos[0];\n    int c = out_pos[1];\n    int y = out_pos[2];\n    int x = out_pos[3];\n    // X、Y方向的移动步长\n    int oy_base = out_pos[2] * stride_v - padTop;\n    int ox_base = out_pos[3] * stride_h - padLeft;\n    for (int fy = 0; fy < height_shape_pool; fy++) {\n        int oy = oy_base + fy;\n        if (oy >= height_shape_origin) {\n            break;\n        }\n        if (oy < 0) {\n            continue;\n        }\n        for (int fx = 0; fx < width_shape_pool; fx++) {\n            int ox = ox_base + fx;\n            if (ox >= width_shape_origin) {\n                break;\n            }\n            if (ox < 0) {\n                continue;\n            }\n            // origin数据\n            float curr = getValueFromTensorPosLIMIT_ORIGIN_origin(out_pos[0], out_pos[1], oy, ox);\n            res = max(res, curr);\n        }\n    } \n    setOutput(res);\n    // outColor.r = float(b);\n    //     outColor.g = float(c);\n    //     outColor.b = float(y);\n    //     outColor.a = float(x);\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}}],conf:["KSIZE_X","KSIZE_Y","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","STRIDES_X","STRIDES_Y","PADDING_X","PADDING_Y"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},pool2d_winograd:{params:"\n// 常量\n// 池化大小\nconst int width_shape_pool = KSIZE_X;\nconst int height_shape_pool = KSIZE_Y;\nconst int type_pool = TYPE_POOL;\n// 输入数据\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\nconst int offset_x_origin = OFFSET_X_ORIGIN;\nconst int offset_y_origin = OFFSET_Y_ORIGIN;\n\n\n// 计算相关\n// 拆分步长\nconst int stride_h = STRIDES_X;\nconst int stride_v = STRIDES_Y;\n// padding的数目\nconst int padLeft = PADDINGS_X;\nconst int padTop = PADDINGS_Y;\n\n\n// uniform变量\nuniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    float res = (-1.0 / exp(-20.0));\n    // 获取output的坐标\n    ivec4 out_pos = getOutputTensorPos();\n    // int b = out_pos[0];\n    // int c = out_pos[1];\n    // int y = out_pos[2];\n    // int x = out_pos[3];\n    // X、Y方向的移动步长\n    int count_pool = 0;\n    int oy_base = out_pos[2] * stride_v - padTop;\n    int ox_base = out_pos[3] * stride_h - padLeft;\n    // int offset = 0;\n    // vec4 v4 = texture(texture_origin, vec2((float(0) + 0.5) / float(width_texture_origin), (float(1 * height_shape_origin / 2 + 0) + 0.5) / float(height_texture_origin)));\n    for (int fy = 0; fy < height_shape_pool; fy++) {\n        int oy = oy_base + fy;\n        if (oy >= height_shape_origin) {\n            break;\n        }\n        if (oy < 0) {\n            continue;\n        }\n        for (int fx = 0; fx < width_shape_pool; fx++) {\n            int ox = ox_base + fx;\n            if (ox >= width_shape_origin) {\n                break;\n            }\n            if (ox < 0) {\n                continue;\n            }\n            // origin数据\n            float curr = getValueFromTensorPosPacked_origin(out_pos[0], out_pos[1], oy, ox);\n            // y = oy;\n            // x = ox;\n            // v4[offset++] = curr;\n            if (type_pool == 1) {\n                if (curr > res) {\n                    res = curr;\n                }\n            } else {\n                res += curr;\n                // 在平均池化模式忽略填充值(exclusive默认为true）\n                count_pool++;\n            }\n        }\n    }\n    if (type_pool != 1) {\n        res = res / float(count_pool);\n    }\n    setOutput(res);\n    // outColor = v4;\n    // outColor.r = float(b);\n    // outColor.g = float(c);\n    // outColor.b = float(y);\n    // outColor.a = float(x);\n}\n",confs:{dep:[{func:"getValueFromTensorPosPacked",conf:{TENSOR_NAME:"origin"}}],conf:["KSIZE_X","KSIZE_Y","TYPE_POOL","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","OFFSET_X_ORIGIN","OFFSET_Y_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","STRIDES_X","STRIDES_Y","PADDING_X","PADDING_Y"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},elementwise_add:{params:"\n    // 输入数据\n    const int axis = AXIS;\n    const int width_shape_origin = WIDTH_SHAPE_ORIGIN;\n    const int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\n    const int length_shape_origin = LENGTH_SHAPE_ORIGIN;\n    const int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\n    const int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\n    const int channel_origin = CHANNEL_ORIGIN;\n\n    const int height_shape_counter = HEIGHT_SHAPE_COUNTER;\n    const int width_shape_counter = WIDTH_SHAPE_COUNTER;\n    const int length_shape_counter = LENGTH_SHAPE_COUNTER;\n    const int width_texture_counter = WIDTH_TEXTURE_COUNTER;\n    const int height_texture_counter = HEIGHT_TEXTURE_COUNTER;\n    const int channel_counter = CHANNEL_COUNTER;\n    \n    uniform sampler2D texture_origin;\n\tuniform sampler2D texture_counter;\n\n",func:"\n// start函数\nvoid main(void) {\n    // 输出数据\n    ivec4 oPos = getOutputTensorPosLIMIT_OUT();\n    float o = getValueFromTensorPosLIMIT_ORIGIN_origin(oPos.r, oPos.g, oPos.b, oPos.a);\n\tivec4 pos_counter;\n\tfloat c = 0.0;\n\n\tif (axis == 1){\n        c = getValueFromTensorPosLIMIT_COUNTER_counter(0, oPos.r, oPos.g, oPos.b);\n    }\n    else if (axis == 2){\n        c = getValueFromTensorPosLIMIT_COUNTER_counter(0, 0, oPos.r, oPos.g);\n    }\n    else if (axis == 3){\n        c = getValueFromTensorPosLIMIT_COUNTER_counter(0, 0, 0, oPos.r);\n    }\n    else {\n        c = getValueFromTensorPosLIMIT_COUNTER_counter(oPos.r, oPos.g, oPos.b, oPos.a);\n    }\n\tfloat res = c + o;\n\tsetOutput(float(res));\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"transferFromNHWCtoNCHW",conf:{}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"counter"}}],conf:["WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_COUNTER","HEIGHT_SHAPE_COUNTER","LENGTH_SHAPE_COUNTER","WIDTH_TEXTURE_COUNTER","HEIGHT_TEXTURE_COUNTER","CHANNEL_COUNTER","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","AXIS"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"counter",variable:"texture",setter:"initTexture",type:"texture"}]}},mul:{params:"\n// mul的input数据\n// 常量\n// 输入数据\nconst int length_shape_counter = LENGTH_SHAPE_COUNTER;\nconst int width_shape_counter = WIDTH_SHAPE_COUNTER;\nconst int height_shape_counter = HEIGHT_SHAPE_COUNTER;\nconst int width_texture_counter = WIDTH_TEXTURE_COUNTER;\nconst int height_texture_counter = HEIGHT_TEXTURE_COUNTER;\nconst int channel_counter = CHANNEL_COUNTER;\n\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\n\n// uniform变量\n// 输入数据\nuniform sampler2D texture_counter;\nuniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    float res = 0.0;\n    // 获取output的坐标\n    ivec4 out_pos = getOutputTensorPosLIMIT_OUT();\n    for (int j = 0; j < width_shape_origin; j++) {\n        float c = getValueFromTensorPosLIMIT_COUNTER_counter(out_pos[0], out_pos[1], j, out_pos[3]);\n        float o = getValueFromTensorPosLIMIT_COUNTER_origin(out_pos[0], out_pos[1], out_pos[2], j);\n        res += c * o;\n    }\n    setOutput(res);\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"counter"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}}],conf:["LENGTH_SHAPE_COUNTER","WIDTH_SHAPE_COUNTER","HEIGHT_SHAPE_COUNTER","WIDTH_TEXTURE_COUNTER","HEIGHT_TEXTURE_COUNTER","CHANNEL_COUNTER","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT"],input:[{tensor:"counter",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},fc:{params:"\n// mul的input数据\n// 常量\n// 输入数据\n// weight\nconst int length_shape_weight = LENGTH_SHAPE_WEIGHT;\nconst int width_shape_weight = WIDTH_SHAPE_WEIGHT;\nconst int height_shape_weight = HEIGHT_SHAPE_WEIGHT;\nconst int width_texture_weight = WIDTH_TEXTURE_WEIGHT;\nconst int height_texture_weight = HEIGHT_TEXTURE_WEIGHT;\nconst int channel_weight = CHANNEL_WEIGHT;\n\n//input\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\n\n// bias\nconst int width_shape_bias = WIDTH_SHAPE_BIAS;\nconst int height_shape_bias = HEIGHT_SHAPE_BIAS;\nconst int length_shape_bias = LENGTH_SHAPE_BIAS;\nconst int width_texture_bias = WIDTH_TEXTURE_BIAS;\nconst int height_texture_bias = HEIGHT_TEXTURE_BIAS;\nconst int channel_bias = CHANNEL_BIAS;\n\n\n// uniform变量\n// 输入数据\nuniform sampler2D texture_weight;\nuniform sampler2D texture_origin;\nuniform sampler2D texture_bias;\n",func:"\n    // start函数\n    void main(void) {\n        float res = 0.0;\n        ivec4 out_pos = getOutputTensorPosLIMIT_OUT();\n        float bias = getValueFromTensorPosLIMIT_BIAS_bias(out_pos.r, out_pos.g, out_pos.b, out_pos.a);\n\n        for (int j = 0; j < width_shape_origin; j++) {\n            float w = getValueFromTensorPosLIMIT_WEIGHT_weight(out_pos[0], out_pos[1], j, out_pos[3]);\n            float o = getValueFromTensorPosLIMIT_ORIGIN_origin(out_pos[0], out_pos[1], out_pos[2], j);\n            res += w * o;\n        }\n\n        res = res + bias;\n        setOutput(res);\n    }\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"weight"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"bias"}}],conf:[],input:[{tensor:"weight",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"bias",variable:"texture",setter:"initTexture",type:"texture"}]}},concat:{params:"\n// mul的input数据\nconst int axis = AXIS;\n\n// 常量\n// 输入数据\nconst int length_shape_counter = LENGTH_SHAPE_COUNTER;\nconst int width_shape_counter = WIDTH_SHAPE_COUNTER;\nconst int height_shape_counter = HEIGHT_SHAPE_COUNTER;\nconst int width_texture_counter = WIDTH_TEXTURE_COUNTER;\nconst int height_texture_counter = HEIGHT_TEXTURE_COUNTER;\nconst int channel_counter = CHANNEL_COUNTER;\nconst int total_shape_counter = TOTAL_SHAPE_COUNTER;\n\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\nconst int total_shape_origin = TOTAL_SHAPE_ORIGIN;\n\nconst int total_shape_out = TOTAL_SHAPE_OUT;\n\nconst int dim = DIM;\nconst int inputs_dim = INPUTS_DIM;\n\n\n// uniform变量\n// 输入数据\nuniform sampler2D texture_counter;\nuniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    ivec4 oPos = getOutputTensorPosLIMIT_OUT();\n    // 输出坐标转换为输入坐标\n//\tint sumVal = oPos.g + oPos.a * channel_out + oPos.b * channel_out * width_shape_out + oPos.r * channel_out * width_shape_out * height_shape_out;\n //   ivec4 new_oPos = transferFromNHWCtoNCHW(sumVal, channel_out, width_shape_out, height_shape_out, total_shape_out);\n    float o = 0.0;\n    if (oPos[dim] > inputs_dim - 1) {\n        oPos[dim] = oPos[dim] - inputs_dim;\n        o = getValueFromTensorPosLIMIT_COUNTER_counter(oPos.r, oPos.g, oPos.b, oPos.a);\n    }\n    else {\n        o = getValueFromTensorPosLIMIT_ORIGIN_origin(oPos.r, oPos.g, oPos.b, oPos.a);\n    }\n\tsetOutput(float(o));\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"counter"}},{func:"transferFromNHWCtoNCHW"}],conf:["LENGTH_SHAPE_COUNTER","WIDTH_SHAPE_COUNTER","HEIGHT_SHAPE_COUNTER","WIDTH_TEXTURE_COUNTER","HEIGHT_TEXTURE_COUNTER","CHANNEL_COUNTER","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"counter",variable:"texture",setter:"initTexture",type:"texture"}]}},concat_mul:{params:"\n// mul的input数据\nconst int axis = AXIS;\n\n// 常量\n// 输入数据\nconst int length_shape_counter = LENGTH_SHAPE_COUNTER;\nconst int width_shape_counter = WIDTH_SHAPE_COUNTER;\nconst int height_shape_counter = HEIGHT_SHAPE_COUNTER;\nconst int width_texture_counter = WIDTH_TEXTURE_COUNTER;\nconst int height_texture_counter = HEIGHT_TEXTURE_COUNTER;\nconst int channel_counter = CHANNEL_COUNTER;\nconst int total_shape_counter = TOTAL_SHAPE_COUNTER;\n\nconst int length_shape_appender = LENGTH_SHAPE_APPENDER;\nconst int width_shape_appender = WIDTH_SHAPE_APPENDER;\nconst int height_shape_appender = HEIGHT_SHAPE_APPENDER;\nconst int width_texture_appender = WIDTH_TEXTURE_APPENDER;\nconst int height_texture_appender = HEIGHT_TEXTURE_APPENDER;\nconst int channel_appender = CHANNEL_APPENDER;\nconst int total_shape_appender = TOTAL_SHAPE_APPENDER;\n\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\nconst int total_shape_origin = TOTAL_SHAPE_ORIGIN;\n\nconst int total_shape_out = TOTAL_SHAPE_OUT;\n\nconst int dim = DIM;\nconst int inputs_dim = INPUTS_DIM;\nconst int append_num = APPEND_NUM;\n\n\n// uniform变量\n// 输入数据\nuniform sampler2D texture_counter;\nuniform sampler2D texture_appender;\nuniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    ivec4 oPos = getOutputTensorPosLIMIT_OUT();\n    // 输出坐标转换为输入坐标\n    float o = 0.0;\n    int dim_total = inputs_dim + append_num;\n\n    if (oPos[dim] < inputs_dim - 1) {\n        o = getValueFromTensorPosLIMIT_ORIGIN_origin(oPos.r, oPos.g, oPos.b, oPos.a);\n    }\n    else if (oPos[dim] < dim_total - 1) {\n        o = getValueFromTensorPosLIMIT_COUNTER_counter(oPos.r, oPos.g, oPos.b, oPos.a);\n    }\n    else {\n        o = getValueFromTensorPosLIMIT_APPENDER_appender(oPos.r, oPos.g, oPos.b, oPos.a);\n    }\n\tsetOutput(float(o));\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"counter"}},{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"appender"}},{func:"transferFromNHWCtoNCHW"}],conf:["LENGTH_SHAPE_COUNTER","WIDTH_SHAPE_COUNTER","HEIGHT_SHAPE_COUNTER","WIDTH_TEXTURE_COUNTER","HEIGHT_TEXTURE_COUNTER","CHANNEL_COUNTER","LENGTH_SHAPE_APPENDER","WIDTH_SHAPE_APPENDER","HEIGHT_SHAPE_APPENDER","WIDTH_TEXTURE_APPENDER","HEIGHT_TEXTURE_APPENDER","CHANNEL_APPENDER","WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"counter",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"appender",variable:"texture",setter:"initTexture",type:"texture"}]}},split:{params:"\n// 常量\n\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\nconst int total_shape_origin = TOTAL_SHAPE_ORIGIN;\n\nconst int total_shape_out = TOTAL_SHAPE_OUT;\n\nconst int dim = DIM;\nconst int num = NUM;\nconst int target_length = TARGET_LENGTH;\n\n\n// 输入数据\nuniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    int length = int(target_length / num);\n    ivec4 oPos = getOutputTensorPos();\n    // 输出坐标转换为输入坐标\n\t//int sumVal = oPos.g + oPos.a * channel_out + oPos.b * channel_out * width_shape_out + oPos.r * channel_out * width_shape_out * height_shape_out;\n    //ivec4 new_oPos = transferFromNHWCtoNCHW(sumVal, channel_out, width_shape_out, height_shape_out, total_shape_out);\n    oPos[dim] = oPos[dim] + layer_run_time * length;\n\tfloat o = getValueFromTensorPos_origin(oPos.r, oPos.g, oPos.b, oPos.a);\n\tsetOutput(float(o));\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"transferFromNHWCtoNCHW"}],conf:["WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},relu:{params:H,func:R,confs:N},relu6:{params:H,func:R,confs:N},scale:{params:H,func:R,confs:N},softmax:{params:"\n// 输入数据\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int total_shape_origin = TOTAL_SHAPE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\nconst int axis = AXIS;\n// uniform变量\n// 输入数据\nuniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    ivec4 oPos = getOutputTensorPos();\n    const int n = int(total_shape_origin/channel_origin/height_shape_origin/width_shape_origin);\n    float o = getValueFromTensorPos_origin(oPos[0], oPos[1], oPos[2], oPos[3]);\n    // 输出坐标转换为输入坐标\n    float total = 0.0;\n    float res = 0.0;\n    if (axis == 0) {\n        for (int i = 0; i < n; i++){\n        float temp = getValueFromTensorPos_origin(i, oPos[1], oPos[2], oPos[3]);\n        total += exp(temp);\n        }\n        res = exp(o) / total;\n    }\n    else if (axis == 1) {\n        for (int i = 0; i < channel_origin; i++){\n        float temp = getValueFromTensorPos_origin(oPos[0], i, oPos[2], oPos[3]);\n        total += exp(temp);\n        }\n        res = exp(o) / total;\n    }\n    else if (axis == 2) {\n        for (int i = 0; i < height_shape_origin; i++){\n        float temp = getValueFromTensorPos_origin(oPos[0], oPos[1], i, oPos[3]);\n        total += exp(temp);\n        }\n        res = exp(o) / total;\n    }\n    else {\n        for (int i = 0; i < width_shape_origin; i++){\n        float temp = getValueFromTensorPos_origin(oPos[0], oPos[1], oPos[2], i);\n        total += exp(temp);\n        }\n        res = exp(o) / total;\n    }\n    setOutput(res);\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}}],conf:["WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},batchnorm:{params:"\n// 输入数据\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\nconst int total_shape_origin = TOTAL_SHAPE_ORIGIN;\n// 计算数据\nconst float epsilon = float(EPSILON);\nconst int width_texture_bias = WIDTH_TEXTURE_BIAS;\nconst int height_texture_bias = HEIGHT_TEXTURE_BIAS;\nconst int width_texture_variance = WIDTH_TEXTURE_VARIANCE;\nconst int height_texture_variance = HEIGHT_TEXTURE_VARIANCE;\nconst int width_texture_mean = WIDTH_TEXTURE_MEAN;\nconst int height_texture_mean = HEIGHT_TEXTURE_MEAN;\nconst int width_texture_scale = WIDTH_TEXTURE_SCALE;\nconst int height_texture_scale = HEIGHT_TEXTURE_SCALE;\n// 输入数据\nuniform sampler2D texture_origin;\nuniform sampler2D texture_scale;\nuniform sampler2D texture_bias;\nuniform sampler2D texture_variance;\nuniform sampler2D texture_mean;\n",func:"\n// start函数\nvoid main(void) {\n    // 输出数据\n    ivec4 oPos = getOutputTensorPosLIMIT_OUT();\n    float o = getValueFromTensorPosLIMIT_ORIGIN_origin(oPos.r, oPos.g, oPos.b, oPos.a);\n\n    // 归一化数据\n    vec4 scale = getPixelsFromTexturePos_texture_scale(vec2( float(oPos.g) / float(width_texture_scale) + 0.00001, 0.0));\n    vec4 bias = getPixelsFromTexturePos_texture_bias(vec2( float(oPos.g) / float(width_texture_bias) + 0.00001, 0.0));\n    vec4 mean = getPixelsFromTexturePos_texture_mean(vec2((float(oPos.g)) / float(width_texture_mean)  + 0.00001, 0.0));\n    vec4 variance = getPixelsFromTexturePos_texture_variance(vec2((float(oPos.g)) / float(width_texture_variance)  + 0.00001, 0.0));\n\n    float x = (o - mean[0]) / sqrt(variance[0] + epsilon);\n    float res = scale[0] * x + bias[0];\n    setOutput(res);\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"getPixelsFromTexturePos",conf:{TEXTURE_NAME:"texture_scale"}},{func:"getPixelsFromTexturePos",conf:{TEXTURE_NAME:"texture_bias"}},{func:"getPixelsFromTexturePos",conf:{TEXTURE_NAME:"texture_variance"}},{func:"getPixelsFromTexturePos",conf:{TEXTURE_NAME:"texture_mean"}},{func:"getPixelsFromTexturePos",conf:{TEXTURE_NAME:"texture_origin"}}],conf:["WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","TOTAL_SHAPE_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","EPSILON","WIDTH_TEXTURE_SCALE","HEIGHT_TEXTURE_SCALE","WIDTH_TEXTURE_BIAS","HEIGHT_TEXTURE_BIAS","WIDTH_TEXTURE_MEAN","HEIGHT_TEXTURE_MEAN","WIDTH_TEXTURE_VARIANCE","HEIGHT_TEXTURE_VARIANCE","MULTI_VALUE","BIAS_VALUE","ACTIVE_FUNCTION"],input:[{tensor:"scale",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"bias",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"mean",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"variance",variable:"texture",setter:"initTexture",type:"texture"},{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},reshape2:{params:"\n// 输入数据\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\nconst int total_shape_origin = TOTAL_SHAPE_ORIGIN;\n\n\n// 输入数据\n uniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    // 输出数据\n\tivec4 oPos = getOutputTensorPos();\n    // 输出坐标转换为输入坐标\n\tint sumVal = oPos.a + oPos.b * width_shape_out + oPos.g * height_shape_out * width_shape_out + oPos.r * channel_out * width_shape_out * height_shape_out;\n \tivec4 new_oPos = transferFromNHWCtoNCHW(sumVal, channel_origin, width_shape_origin, height_shape_origin, total_shape_origin);\n\tfloat o = getValueFromTensorPos_origin(new_oPos.r, new_oPos.g, new_oPos.b, new_oPos.a);\n\tsetOutput(float(o));\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"transferFromNHWCtoNCHW",conf:{}}],conf:["WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","MULTI_VALUE","BIAS_VALUE","ACTIVE_FUNCTION"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},bilinear_interp:{params:"\n// 输入数据\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\nconst int total_shape_origin = TOTAL_SHAPE_ORIGIN;\nconst int total_shape_out = TOTAL_SHAPE_OUT;\n// 输入数据\n uniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    // 输出数据\n\tivec4 oPos = getOutputTensorPosLIMIT_OUT();\n    // 输出坐标转换为输入坐标\n\t//int sumVal = oPos.g + oPos.a * channel_out + oPos.b * channel_out * width_shape_out + oPos.r * channel_out * width_shape_out * height_shape_out;\n \t//oPos = transferFromNHWCtoNCHW(sumVal, channel_out, width_shape_out, height_shape_out, total_shape_out);\n\tfloat o = getValueFromTensorPosLIMIT_ORIGIN_origin(oPos.r, oPos.g, oPos.b, oPos.a);\n\tfloat scale_x = float(width_shape_out - 1) / float(width_shape_origin - 1);\n    float scale_y = float(height_shape_out - 1) / float(height_shape_origin - 1);\n    float x = float(oPos.a) / scale_x;\n    float y = float(oPos.b) / scale_y;\n\tint x1 = int(floor(x));\n\tint y1 = int(floor(y));\n\tint x2 = int(ceil(x));\n\tint y2 = int(ceil(y));\n\tfloat dist_x = x - float(x1);\n    float dist_y = y - float(y1);\n    float value11 = getValueFromTensorPosLIMIT_ORIGIN_origin(oPos.r, oPos.g, y1, x1);\n    float value12 = getValueFromTensorPosLIMIT_ORIGIN_origin(oPos.r, oPos.g, y2, x1);\n    float value21 = getValueFromTensorPosLIMIT_ORIGIN_origin(oPos.r, oPos.g, y1, x2);\n    float value22 = getValueFromTensorPosLIMIT_ORIGIN_origin(oPos.r, oPos.g, y2, x2);\n    float value = (1.0 - dist_x) * (1.0 - dist_y) * value11 +\n            (1.0 - dist_x) * dist_y * value12 + dist_x * (1.0 - dist_y) * value21 +\n            dist_x * dist_y * value22;\n    setOutput(float(value));\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"transferFromNHWCtoNCHW",conf:{}}],conf:["WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","MULTI_VALUE","BIAS_VALUE","ACTIVE_FUNCTION"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}},transpose2:{params:"\n// 输入数据\nconst int width_shape_origin = WIDTH_SHAPE_ORIGIN;\nconst int height_shape_origin = HEIGHT_SHAPE_ORIGIN;\nconst int length_shape_origin = LENGTH_SHAPE_ORIGIN;\nconst int width_texture_origin = WIDTH_TEXTURE_ORIGIN;\nconst int height_texture_origin = HEIGHT_TEXTURE_ORIGIN;\nconst int channel_origin = CHANNEL_ORIGIN;\nconst int total_shape_origin = TOTAL_SHAPE_ORIGIN;\n\n\nconst int perm_size = PERM_SIZE;\nconst int perm_0 = PERM_0;\nconst int perm_1 = PERM_1;\nconst int perm_2 = PERM_2;\nconst int perm_3 = PERM_3;\n\n// 输入数据\n uniform sampler2D texture_origin;\n",func:"\n// start函数\nvoid main(void) {\n    // 输出数据\n\tivec4 oPos = getOutputTensorPos();\n\t    // 重排遍历顺序\n\t//int sumVal = oPos.g + oPos.a * channel_out + oPos.b * channel_out * width_shape_out + oPos.r * channel_out * width_shape_out * height_shape_out;\n\t//ivec4 new_oPos = transferFromNHWCtoNCHW(sumVal, channel_out, width_shape_out, height_shape_out, total_shape_origin);\n\n\t// 转置 坐标变换\n\t//oPos = new_oPos;\n\tfloat o = 0.0;\n\tif (perm_size == 1) {\n\t\to = getValueFromTensorPos_origin(oPos[0], oPos[1], oPos[2], oPos[3]);\n\t}\n\telse if (perm_size == 2) {\n\t\to = getValueFromTensorPos_origin(oPos[0], oPos[1], oPos[(2 + perm_0)>3?3:(2 + perm_0)], oPos[(2 + perm_1)>3?3:(2 + perm_1)]);\n\t}\n\telse if (perm_size == 3) {\n\t\to = getValueFromTensorPos_origin(oPos[0], oPos[(1 + perm_0)>3?3:(1 + perm_0)], oPos[(1 + perm_1)>3?3:(1 + perm_1)], oPos[(1 + perm_2)>3?3:(1 + perm_2)]);\n\t}\n\telse if (perm_size == 4) {\n\t\to = getValueFromTensorPos_origin(oPos[perm_0], oPos[perm_1], oPos[perm_2], oPos[perm_3]);\n\t}\n\n\n\tsetOutput(float(o));\n}\n",confs:{dep:[{func:"getValueFromTensorPos",conf:{TENSOR_NAME:"origin"}},{func:"transferFromNHWCtoNCHW",conf:{}}],conf:["WIDTH_SHAPE_ORIGIN","HEIGHT_SHAPE_ORIGIN","LENGTH_SHAPE_ORIGIN","WIDTH_TEXTURE_ORIGIN","HEIGHT_TEXTURE_ORIGIN","CHANNEL_ORIGIN","WIDTH_SHAPE_OUT","HEIGHT_SHAPE_OUT","WIDTH_TEXTURE_OUT","HEIGHT_TEXTURE_OUT","CHANNEL_OUT","OFFSET_Y_OUT","MULTI_VALUE","BIAS_VALUE","ACTIVE_FUNCTION"],input:[{tensor:"origin",variable:"texture",setter:"initTexture",type:"texture"}]}}},atoms:{getArrayIndexFromTensorPos:"\n\nint getArrayIndexFromTensorPos_TENSOR_NAME(TENSOR_TYPE tensorPos) {\n    int index = 0;\n    for (int i = 0; i < length_shape_TENSOR_NAME; i++) {\n        index += tensorPos[i] * numbers_shape_TENSOR_NAME[i];\n    }\n    return index;\n}\n",getArrayIndexFromTexturePos:"\nint getArrayIndexFromTexturePos_TEXTURE_NAME(vec3 pos) {\n    int x = int(floor(pos.x));\n    int y = int(floor(pos.y));\n    int d = int(floor(pos.z));\n    return (width_TEXTURE_NAME * y + x) * 4 + d;\n}\n",getTensorPosFromArrayIndex:"\niTENSOR_TYPE getTensorPosFromArrayIndex_TENSOR_NAME(int n) {\n    iTENSOR_TYPE pos;\n    pos[0] = n / numbers_shape_TENSOR_NAME[0];\n    for (int i = 1; i < length_shape_TENSOR_NAME; i++) {\n        n = int(mod(float(n), float(numbers_shape_TENSOR_NAME[i - 1])));\n        pos[i] = n / numbers_shape_TENSOR_NAME[i];\n    }\n    return pos;\n}\n",getTexturePosFromArrayIndex:"\nvec3 getTexturePosFromArrayIndex_TEXTURE_NAME(int n) {\n    vec3 pos;\n    pos.z = mod(float(n), 4.0);\n    n /= 4;\n    int y = n / width_TEXTURE_NAME;\n    float width = float(width_TEXTURE_NAME);\n    float x = mod(float(n), width);\n    pos.x = x / width;\n    pos.y = float(y) / float(height_TEXTURE_NAME);\n    return pos;\n}\n",getValueFromTexturePos:"\nfloat getValueFromTexturePos_TEXTURE_NAME(vec3 pos) {\n    vec4 pixels = TEXTURE2D(TEXTURE_NAME, pos.xy);\n    int d = int(pos.z);\n    if (d == 0) {\n        return pixels.r;\n    } else if (d == 1) {\n        return pixels.g;\n    } else if (d == 2) {\n        return pixels.b;\n    }\n    return pixels.a;\n}\n",getValueFromTensorPos:"\n// 根据tensor坐标获取这个tensor位置的值\nfloat getValueFromTensorPos_TENSOR_NAME(int r, int g, int b, int a) {\n    vec4 pixels = TEXTURE2D(texture_TENSOR_NAME,\n        vec2(\n            (float(a * channel_TENSOR_NAME + g) + 0.5) / float(width_texture_TENSOR_NAME),\n            (float(r * height_shape_TENSOR_NAME + b) + 0.5) / float(height_texture_TENSOR_NAME)\n        )\n    );\n    // 只用了r通道\n    return pixels.r;\n}\n\n// 超限布局根据tensor坐标获取这个tensor位置的值\nfloat getValueFromTensorPosLimit_TENSOR_NAME(int r, int g, int b, int a) {\n    float pieceW = ceil(float(width_shape_TENSOR_NAME) / 4.0);\n    int x = int(mod(float(a), pieceW));\n    int offsetY = 0;\n\n    if ((float(a) / pieceW) >= 3.0) {\n        offsetY = 3 * height_shape_TENSOR_NAME;\n    }\n    else if (float(a) / pieceW >= 2.0) {\n        offsetY = 2 * height_shape_TENSOR_NAME;\n    }\n    else if (float(a) >= pieceW) {\n        offsetY = height_shape_TENSOR_NAME;\n    }\n    vec4 pixels = TEXTURE2D(texture_TENSOR_NAME,\n        vec2(\n            (float(x * channel_TENSOR_NAME + g) + 0.5) / float(width_texture_TENSOR_NAME),\n            (float(r * 4 * height_shape_TENSOR_NAME + b + offsetY) + 0.5) / float(height_texture_TENSOR_NAME)\n        )\n    );\n    return pixels.r;\n}\n\n",getValueFromTensorPosPacked:"\nfloat getValueFromTensorPosPacked_TENSOR_NAME(int r, int g, int b, int a) {\n    int y = b / 2;\n    int yOffset = int(mod(float(b), 2.0));\n    int x = a / 2;\n    int xOffset = int(mod(float(a), 2.0));\n    int height = height_shape_TENSOR_NAME + offset_y_TENSOR_NAME;\n    vec4 pixels = TEXTURE2D(texture_TENSOR_NAME, vec2((float(x) + 0.5) / float(width_texture_TENSOR_NAME), (float(g * height / 2 + y) + 0.5) / float(height_texture_TENSOR_NAME)));\n    int index = 0;\n    if (xOffset == 0 && yOffset == 0) {\n        return pixels[0];\n    } \n    else if (xOffset == 1 && yOffset == 0) {\n        return pixels[1];\n    }\n    else if (xOffset == 0 && yOffset == 1) {\n        return pixels[2];\n    }\n    return pixels[3];\n}\n",moveTexture2PosToReal:"\n\n// vec2 moveTexture2PosToReal_TEXTURE_NAME(vec2 v) {\n//     return v * _2d_shape_TEXTURE_NAME;\n//     // vec2 v2;\n//     // v2.x = v.x * float(width_TEXTURE_NAME);\n//     // v2.y = v.y * float(height_TEXTURE_NAME);\n//     // return v2;\n// }\n\nvec2 moveTexture2PosToReal_TEXTURE_NAME(vec2 v) {\n    vec2 v2;\n    v2.x = v.x * float(width_TEXTURE_NAME);\n    v2.y = v.y * float(height_TEXTURE_NAME);\n    return v2;\n}\n",getPixelsFromTexturePos:"\n#define getPixelsFromTexturePos_TEXTURE_NAME(pos) TEXTURE2D(TEXTURE_NAME, pos)\n",getRangeSumFromArrayIndex:"\nfloat getRangeSumFromArrayIndex_TEXTURE_NAME(int start) {\n    float result = 0.0;\n    for (int i = 0; i < (width_shape_TENSOR_NAME * height_shape_TENSOR_NAME); i++) {\n        vec3 pos = getTexturePosFromArrayIndex_TEXTURE_NAME(i + start);\n        result += getValueFromTexturePos_TEXTURE_NAME(pos); \n    }\n    return result;\n}\n",getRangePowSumFromArrayIndex:"\nfloat getRangePowSumFromArrayIndex_TEXTURE_NAME(int start, float p, float mean) {\n    float result = 0.0;\n    for (int i = 0; i < (width_shape_TENSOR_NAME * height_shape_TENSOR_NAME); i++) {\n        vec3 pos = getTexturePosFromArrayIndex_TEXTURE_NAME(i + start);\n        result += pow(getValueFromTexturePos_TEXTURE_NAME(pos) - mean, p); \n    }\n    return result;\n}\n",sigmoid:"\nfloat sigmoid(float x, float y, float z) {\n    float result = 1.0 / (1.0 + exp(-x));\n    return result;\n}\n",prelu:"\nfloat prelu(float x, float p, float b) {\n    float result = x;\n    if (x < 0.0) {\n        result = x * p;\n    }\n    return result;\n}\n",scale:"\nfloat scale(float x, float p, float b) {\n    float result = p * x + b;\n    return result;\n}\n",softmax:"\nfloat softmax(float x, float p, float b) {\n    float result = x;\n    if (x < 0.0) {\n        result = x * p;\n    }\n    return result;\n}\n",transferFromNHWCtoNCHW:"\nivec4 transferFromNHWCtoNCHW( int sumVal,  const int channel, const int width_shape, const int height_shape, const int total_shape) {\n\n\tint n_origin = int(total_shape/(channel * width_shape * height_shape));\n\tint new_a = int(mod(float(sumVal), float(width_shape)));\n\tsumVal = int((sumVal - new_a) / width_shape);\n\tint new_b = int(mod(float(sumVal), float(height_shape)));\n\tsumVal = int((sumVal - new_b) / height_shape);\n\tint new_g = int(mod(float(sumVal), float(channel)));\n\tsumVal = int((sumVal - new_g) / channel);\n\tint new_r = int(mod(float(sumVal), float(n_origin)));\n\treturn ivec4(new_r,new_g,new_b,new_a);\n}\n"}},A=function(){function t(e){r()(this,t),this.defaultOpts=Object.assign({},e),this.webglVersion=2,this.isFrameBufferSupportFloat=!0,this.texture2d="texture"}return a()(t,[{key:"setWebglVersion",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:0;this.webglVersion=t,1===t&&(this.texture2d="texture2D")}},{key:"setIsFrameBufferSupportFloat",value:function(){var t=!(arguments.length>0&&void 0!==arguments[0])||arguments[0];this.isFrameBufferSupportFloat=t}},{key:"buildShader",value:function(t,e){var n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:void 0,i="";return i=this.buildPrefix(t),i+=this.buildCommon(t),i+=void 0!==n?this.buildRuntime(n):"",i+=this.buildOp(t),e.texture2d=this.texture2d,i=this.populateData(i,e)}},{key:"buildPrefix",value:function(t){return 1===this.webglVersion?this.isFrameBufferSupportFloat?P.common.prefix:P.common.prefixHalf:P.common.prefix2}},{key:"buildCommon",value:function(t){return P.common.params+P.common.func}},{key:"buildRuntime",value:function(t){return"\n            int layer_run_time = ".concat(t,";\n        ")}},{key:"buildOp",value:function(t){var e=this,n=P.ops[t].params,i=P.atoms;return(P.ops[t].confs.dep||[]).map((function(t){var r=t.func,o=t.conf,a=i[r];n+=e.populateData(a,o)})),n+=this.buildSuffix(t),n+=P.ops[t].func}},{key:"buildSuffix",value:function(t){return P.common.suffix}},{key:"populateData",value:function(t,e){var n=t;for(var i in e)n=n.replace(new RegExp(i.toUpperCase(),"g"),void 0===e[i]?1:e[i]);return n}},{key:"getOpConfs",value:function(){var t={};for(var e in P.ops)P.ops.hasOwnProperty(e)&&(t[e]=P.ops[e].confs.input);return t}}]),t}(),O=function(){function t(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};r()(this,t),this.gpu=new v(e)}var e;return a()(t,[{key:"getWebglVersion",value:function(){return this.gpu.getWebglVersion()}},{key:"getWebglMaxTextureSize",value:function(){return this.gpu.getWebglMaxTextureSize()}},{key:"getWebglMaxTextureImageUnits",value:function(){return this.gpu.maxTextureImageUnits()}},{key:"getIsFrameBufferSupportFloat",value:function(){return this.gpu.getIsFrameBufferSupportFloat()}},{key:"run",value:function(t,e,n){var i=this;if(!e.isPass)return console.log("跳过当前op："+t),this;var r=this.gpu;e.program.forEach((function(t,o){var a=e.outputTensors[o],s=a.tensorId;r.setOutProps(a),r.attachFrameBuffer(e.iLayer,s),r.setProgram(t,n),i.gpu.render(e.renderData,e.iLayer,n)}))}},{key:"read2",value:function(){return this.gpu.frameBufferIsComplete().isComplete?this.gpu.compute():null}},{key:"read",value:(e=l()(_.a.mark((function t(){var e;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return e=this.gpu.createPBO(),t.next=3,this.gpu.createAndWaitForFence();case 3:return t.abrupt("return",this.gpu.downloadFoat32TensorFromBuffer(e));case 4:case"end":return t.stop()}}),t,this)}))),function(){return e.apply(this,arguments)})},{key:"createProgram",value:function(t,e){var n=this.gpu.initShader(t,"fragment");return this.gpu.createProgram(n,e)}},{key:"dispose",value:function(){this.gpu.dispose()}}]),t}(),y=n(8),S=n.n(y),G=null,U={setTextureMaxSize:function(t){G=t},getQueryTime:function(t,e){return t.getQueryParameter(e,t.QUERY_RESULT)},beginQuery:function(t){var e=t.getExtension("EXT_disjoint_timer_query_webgl2");if(e){var n=t.createQuery();return t.beginQuery(e.TIME_ELAPSED_EXT,n),n}},endQuery:function(t,e){var n=t.getExtension("EXT_disjoint_timer_query_webgl2");if(n)return t.endQuery(n.TIME_ELAPSED_EXT),e},getReshapeInPaddle:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=arguments.length>2&&void 0!==arguments[2]?arguments[2]:[],n=t.reduce((function(t,e){return t*e}));return 1===e.length?[1,n]:[e[0],n/e[0]]},getBroadcastShapeInPaddle:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:[],n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:1,i=t,r=e;return t.length-e.length<0&&(i=e,r=t),r.concat(i.slice(n))},getBroadcastDims:function(){for(var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:[],n=t.length,i=[],r=0;r<n;r++){var o=n-1-r,a=t[o]||1,s=e[e.length-1-r]||1;s>1&&1===a&&i.unshift(o)}return i},getBroadcastShape:function(){for(var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:[],n=[],i=Math.max(t.length,e.length),r=0;r<i;r++){var o=t[t.length-r-1];null===o&&(o=1);var a=e[e.length-r-1];if(null===a&&(a=1),1===o)n.unshift(a);else if(1===a)n.unshift(o);else{if(o!==a)return null;n.unshift(o)}}return n},applyFilterWinograd:function(t,e){for(var n=f()(e,4),i=n[0],r=n[1],o=(n[2],n[3],0),a=0,s=new Float32Array(i*r*16),u=0;u<i;u++)for(var _=0;_<r;_++){var h=t.subarray(a,a+9),l=f()(h,9),c=l[0],T=l[1],p=l[2],E=l[3],d=l[4],I=l[5],g=l[6],m=l[7],x=l[8],v=[c,.5*c+.5*T+.5*p,.5*c-.5*T+.5*p,p,.5*c+.5*E+.5*g,.25*c+.25*T+.25*p+.25*E+.25*d+.25*I+.25*g+.25*m+.25*x,.25*c-.25*T+.25*p+.25*E-.25*d+.25*I+.25*g-.25*m+.25*x,.5*p+.5*I+.5*x,.5*c-.5*E+.5*g,.25*c+.25*T+.25*p-.25*E-.25*d-.25*I+.25*g+.25*m+.25*x,.25*c-.25*T+.25*p-.25*E+.25*d-.25*I+.25*g-.25*m+.25*x,.5*p-.5*I+.5*x,g,.5*g+.5*m+.5*x,.5*g-.5*m+.5*x,x];s.set(v,o),o+=16,a+=9}return s},getTextureInfoFromTensorShape:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=arguments.length>1&&void 0!==arguments[1]&&arguments[1],n=t[0],i=t[1],r=t[2],o=t[3],a=n*r,s=i*o,u=0,_=0,h=!1;if((a>G||s>G)&&(console.error("大小超限",t),a*=4,s=i*Math.ceil(o/4),h=!0,a>G||s>G)){var l="[".concat(s,"x").concat(a,"]"),c="[".concat(G,"x").concat(G,"]");throw new Error("Requested texture size "+l+" greater than WebGL maximum on this browser / GPU "+c+".")}return e&&(a=n*i*Math.ceil(r/2),s=Math.ceil(o/2),u=o%2,_=r%2),{offsetX:u,offsetY:_,exceedMax:h,shape:[4,a,s],zeroNumber:0}},getMaxItem:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=Math.max.apply(null,t),n=t.indexOf(e);return{value:e,index:n}},loadShader:function(t){var e=this;return l()(_.a.mark((function n(){var i;return _.a.wrap((function(n){for(;;)switch(n.prev=n.next){case 0:return n.next=2,fetch(e.getShaderFile(t));case 2:return i=n.sent,n.abrupt("return",i.text());case 4:case"end":return n.stop()}}),n)})))()},getShaderFile:function(t){var e=t.split("/");return"/"+e[e.length-1]},img2texture:function(){for(var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},e=t.height_texture,n=t.width_texture,i=t.shape,r=e*n*4,o=i[0],a=i[1],s=i[2],u=i[3],_=new Float32Array(o*a*s*u*4),h=0,l=0;l<r;l++){var c=l/(a*u)|0,f=l%(a*u),T=c/s|0,p=c%s,E=f%a,d=f/a|0,I=T*(a*s*u)+E*(s*u)+p*u+d;_[h]=t.data[I],h+=4}t.data=_},padToFourDimShape:function(t){var e=[];if(4==t.length)e=t;else if(t.length<4){for(var n=0;n<4-t.length;n++)e.push(1);e=e.concat(t)}return e},nhwc2nchw:function(t,e){for(var n=e[0],i=e[1],r=e[2],o=e[3],a=r*o,s=i*r*o,u=[],_=0;_<n;_++)for(var h=0;h<o;h++)for(var l=0;l<i;l++)for(var c=0;c<r;c++)u.push(t[_*s+l*a+c*o+h]);return u},nchw2nhwc:function(t,e){for(var n=e[0],i=e[1],r=e[2],o=e[3],a=r*o,s=i*r*o,u=[],_=0;_<n;_++)for(var h=0;h<r;h++)for(var l=0;l<o;l++)for(var c=0;c<i;c++)u.push(t[_*s+c*a+h*o+l]);return u},stridePrint:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:20,n=e;if(t.length<=n)this.continuousPrint(t,n);else{var i=[],r=Math.floor(t.length/n);0==r&&(r=1),n=Math.floor(t.length/r);for(var o=0;o<n;o++)i.push(o*r+": "+t[o*r])}},continuousPrint:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:100,n=[],i=e;t.length<=i&&(i=t.length);for(var r=0;r<i;r++)n.push(r+": "+t[r])},softmax:function(t){for(var e=new Float32Array(t.length),n=t[0],i=0,r=0,o=1;o<t.lenght;o++)n<(i=t[o])&&(n=i);for(var a=0;a<t.length;a++)i=Math.exp(t[a]-n),e[a]=i,r+=i;for(var s=0;s<t.length;s++)e[s]=e[s]/r;return e},formatReadData:function(t,e){if(e.length<4){for(var n=[],i=0;i<4-e.length;i++)n.push(1);e=n.concat(e)}var r=e[0],o=e[1],a=e[2],s=e[3];if(r*a<=G&&o*s<=G)return t;for(var u=0,_=[],h=Math.ceil(s/4),l=0;l<r;l++)for(var c=0;c<o;c++)for(var f=0;f<a;f++)for(var T=0;T<s;T++)u=Math.floor(T/h)*h*(a-1)+T+f*h,u+=l*o*a*s+c*a*s,_.push(t[u]);return _},toPercent:function(t){return Number(100*t).toFixed(3)+"%"}},L=function(){function t(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};r()(this,t),this.opts=e,this.isPacked=this.isPacked||!1,this.name=e.name,this.tensorId=e.type;var n=this.shape=e.shape;if(this.total=n.reduce((function(t,e){return t*e})),e.needBatch&&n.length<4){for(var i=[],o=0;o<4-n.length;o++)i.push(1);n=i.concat(n),this.shape=n}var a,s=U.getTextureInfoFromTensorShape(n,e.isPacked),u=s.offsetX,_=s.offsetY,h=s.exceedMax,l=(s.zeroNumber,s.shape);if(this.shape_texture=l,this.exceedMax=h,this.offsetX=u,this.offsetY=_,"image"===e.type||"x"===e.type)this.data=e.data;else if(e.data&&e.data.length){if(a=new Float32Array(e.data.length),e.notCompressed)this.shape_texture=[4,1,this.total/4],this.data=new Float32Array(e.data);else{n[0];var c=n[1],f=n[2],T=n[3];if(T){for(var p=0;p<e.data.length;p++){var E=p/(c*T)|0,d=p%(c*T),I=E/f|0,g=E%f,m=d%c,x=d/c|0,v=I*(c*f*T)+m*(f*T)+g*T+x;a[p]=e.data[v]}this.data=a}}e.data=null}}return a()(t,[{key:"getValue",value:function(){for(var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=[].concat(t),n=e.length,i=this.shape.length,r=0;r<i-n;r++)e.unshift(0);for(var o=0,a=0;a<i;a++)o+=e[a]*this.shapeNumbers[a];return this.data[o]}},{key:"dispose",value:function(){this.data&&(this.data=null)}},{key:"width_texture",get:function(){var t=this.shape_texture.length;return this.shape_texture[t-1]}},{key:"height_texture",get:function(){var t=this.shape_texture.length;return this.shape_texture[t-2]}},{key:"width_shape",get:function(){var t=this.shape.length;return this.shape[t-1]}},{key:"height_shape",get:function(){var t=this.shape.length;return this.shape[t-2]}},{key:"channel",get:function(){var t=this.shape.length;return t>=3?this.shape[t-3]:0}},{key:"offset_x",get:function(){return this.offsetX}},{key:"offset_y",get:function(){return this.offsetY}},{key:"limit",get:function(){return this.exceedMax?"Limit":""}},{key:"length_shape",get:function(){return this.shape.length||0}},{key:"numbers_shape",get:function(){for(var t=[],e=this.shape.length,n=0;n<e-1;n++){var i=this.shape.slice(n+1).reduce((function(t,e){return t*e}));t.push(i)}return t.push(1),t}},{key:"total_shape",get:function(){return this.total}}]),t}(),b=["paddings","strides","dilations","ksize"],F=["length_shape","width_shape","height_shape","width_texture","height_texture","offset_x","offset_y","limit","channel","total_shape"],D={scale:{bias:"bias_value",scale:"multi_value"},pool2d:{pooling_type:"type_pool"},pool2d_winograd:{pooling_type:"type_pool"}},w={input:"origin",x:"origin",filter:"filter",y:"counter",z:"appender",output:"out",out:"out",scale:"scale",bias:"bias",mean:"mean",variance:"variance",w:"weight"},C={conv2d:["needBatch","adaptPaddings","isApplySeparableConv"],conv2d_transpose:["needBatch"],batchnorm:["needBatch","mergeTensor"],elementwise_add:["processAxis","needBatch"],conv2d_elementwise_add:["mergeAttrs","setActiveFunc","needBatch"],pool2d:["isMax","needBatch","setPacked","isGlobalPooling"],relu:["transToPrelu","needBatch"],relu6:["transToRelu6","needBatch"],leaky_relu:["transToLeakyrelu","needBatch"],mul:["reshape","needBatch"],bilinear_interp:["needBatch"],reshape2:["needBatch","inferShape"],transpose2:["needBatch","setPerm"],concat:["normalizeDim","needBatch"],concat_mul:["needBatch","processDim","normalizeDim","normalizeDim2"],split:["normalizeDim","needBatch"],softmax:["needBatch"],scale:["needBatch"],fc:["flattenShape","needBatch"]},X=function(){function t(e){var n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},o=arguments.length>3&&void 0!==arguments[3]?arguments[3]:{};r()(this,t),this.realName=e,this.name=e,this.attrs=o,this.checkIsMerge(),this.isPass=this.checkIsPass(),this.isPass&&(this.input=n,this.output=i,this.data={active_function:"scale",multi_value:"1.0",bias_value:"0.0",fuse_relu:!1},this.inputTensors=[],this.outputTensors=[],this.fShaderParams=[],this.buildTensor(),this.buildShaderParams())}return a()(t,[{key:"adaptPaddings",value:function(){for(var t in this.attrs)if(this.attrs.hasOwnProperty(t)&&"paddings"===t){var e=this.attrs[t],n=f()(e,2),i=n[0],r=n[1];return void(0===i&&1===r&&(this.attrs[t][1]=0))}}},{key:"inferShape",value:function(){if("reshape2"==this.name){var t=this.input.X[0].shape;this.attrs.shape&&(this.attrs.new_shape=this.attrs.shape,delete this.attrs.shape);for(var e=this.attrs.new_shape,n=0;n<e.length;n++)0==e[n]&&(e[n]=t[n]);for(var i=1,r=0;r<t.length;r++)i*=t[r];for(var o=-1,a=0;a<e.length;a++)-1!=e[a]?i/=e[a]:o=a;-1!=o&&(e[o]=i),this.output.Out[0].shape=e}}},{key:"buildTensor",value:function(){var t=this,e=[];for(var n in this.input)if(this.input.hasOwnProperty(n)){var i=this.input[n]||[{}];w[n.toLowerCase()]&&(i[0].tensorName=w[n.toLowerCase()],e.push(i[0]))}delete this.output.Y;var r=function(n){if(t.output.hasOwnProperty(n)){var i=t.output[n]||[{}];w[n.toLowerCase()]&&i.forEach((function(t){t.tensorName=w[n.toLowerCase()],e.push(t)}))}};for(var o in this.output)r(o);(C[this.name]||[]).forEach((function(n){t[n](e)})),e.forEach((function(e){if(e){var n=null,i=e.tensorName;n=e.notTensor?{name:i,data:new Float32Array(e.data),total_shape:e.data.length}:new L({type:e.name,name:i,shape:e.shape,data:e.data,needBatch:e.needBatch||!1,notCompressed:e.notCompressed||!1,isPacked:e.isPacked||!1}),"out"===i?t.outputTensors.push(n):t.inputTensors.push(n)}}))}},{key:"buildShaderParams",value:function(){var t=this;for(var e in this.attrs)if(this.attrs.hasOwnProperty(e)){var n=this.attrs[e];if(Array.isArray(n)&&b.indexOf(e)>-1)this.data[e+"_x"]=n[0],this.data[e+"_y"]=n[1];else{this.data[e]=n;var i=D[this.name];i&&i.hasOwnProperty(e)&&(this.data[i[e]]=n)}}this.inputTensors.forEach((function(e){F.forEach((function(n){t.data[n+"_"+e.name]=e[n]}))})),this.outputTensors.forEach((function(e){var n=JSON.parse(JSON.stringify(t.data));F.forEach((function(t){n[t+"_"+e.name]=e[t]})),t.fShaderParams.push(n)}))}},{key:"needBatch",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[];t.forEach((function(t){return t.needBatch=!0}))}},{key:"setPerm",value:function(){var t=this.attrs.axis,e=t.length;if(3==e)t==[2,0,1]?t=[1,2,0]:t==[1,2,0]&&(t=[2,0,1]);else if(4==e){for(var n=[0,0,0,0],i=0;i<4;i++)n[[t[i]]]=i;t=n}this.data.perm_0=0,this.data.perm_1=0,this.data.perm_2=0,this.data.perm_3=0,e>=1&&(this.data.perm_0=t[0]),e>=2&&(this.data.perm_1=t[1]),e>=3&&(this.data.perm_2=t[2]),e>=4&&(this.data.perm_3=t[3]),this.data.perm_size=e}},{key:"isGlobalPooling",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=t.filter((function(t){return"origin"===t.tensorName}))[0]||{},n=e.shape&&e.shape.length||0;n>2&&this.attrs.global_pooling&&(this.attrs.ksize=[e.shape[n-2],e.shape[n-1]])}},{key:"mergeAttrs",value:function(){this.attrs=this.attrs.reduce((function(t,e){return Object.assign(t,e)}),{})}},{key:"isApplyWinoGrad",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=t.filter((function(t){var e=f()(t.shape,4),n=(e[0],e[1],e[2]),i=e[3];return 3===n&&3===i&&"filter"===t.tensorName}));e&&e.length&&(this.setPacked(t),this.applyWinograd(t),this.setOutputPacked(t),this.name+="_winograd")}},{key:"isApplySeparableConv",value:function(){var t,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],n=this.attrs.groups,i=!1,r=e.filter((function(e){var r=e.shape,o=e.tensorName;"bias"===o&&(i=!0);var a=f()(r,4),s=a[0],u=a[1];a[2],a[3];return i||t||"out"!==o||(t=u),s===n&&1===u&&"filter"===e.tensorName}));r&&r.length&&(this.name+="_depthwise"),!i&&e.push({name:"conv1_scale_offset",needBatch:!0,persistable:!0,shape:[t],data:Array.from(new Float32Array(t),(function(t){return 0})),tensorName:"bias"})}},{key:"setPacked",value:function(){var t=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],n=this.attrs.ispacked;e.forEach((function(e){"origin"===e.tensorName&&n&&(e.isPacked=!0,t.name.indexOf("pool")>-1&&(t.name+="_winograd"))}))}},{key:"applyWinograd",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[];t.forEach((function(t){if("filter"===t.tensorName){var e=f()(t.shape,4),n=e[0],i=e[1];e[2],e[3];t.shape=[n,i,4,4],t.data=U.applyFilterWinograd(t.data,t.shape)}}))}},{key:"setOutputPacked",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[];t.forEach((function(t){"out"===t.tensorName&&(t.isPacked=!0)}))}},{key:"isMax",value:function(){var t="max"===this.attrs.pooling_type?1:0;this.attrs.pooling_type=t,1===t&&(this.name+="_max")}},{key:"transToPrelu",value:function(){this.data.multi_value="0.0",this.data.active_function="prelu"}},{key:"transToRelu6",value:function(){this.data.multi_value=this.attrs.threshold,this.data.active_function="relu6"}},{key:"transToLeakyrelu",value:function(){this.data.multi_value=this.attrs.alpha,this.data.active_function="leakyRelu",this.name="relu"}},{key:"setActiveFunc",value:function(){"leaky_relu"===this.realName.replace("conv2d-elementwise_add-","")&&(this.data.multi_value=this.attrs.alpha,this.data.active_function="leakyRelu")}},{key:"normalizeDim",value:function(){var t=this.input.X[0].shape;if(t.length<4){for(var e=[],n=0;n<4-t.length;n++)e.push(1);t=e.concat(t)}for(var i=t,r=this.attrs.axis>-1?this.attrs.axis:i.length+this.attrs.axis,o=[],a=0;a<i[r];a++)o[a]=a;this.attrs.target_length=o.length,this.attrs.target_value=o,this.attrs.inputs_dim=i[r],this.attrs.dim=4-i.length+r}},{key:"normalizeDim2",value:function(){var t=this.input.Y[0].shape;if(t.length<4){for(var e=[],n=0;n<4-t.length;n++)e.push(1);t=e.concat(t)}var i=t,r=this.attrs.axis>-1?this.attrs.axis:i.length+this.attrs.axis;this.attrs.append_num=i[r]}},{key:"processDim",value:function(){if(-1!==this.attrs.axis){var t=this.input.X[0].shape;this.attrs.axis+=4-t.length}}},{key:"processAxis",value:function(){var t=this.input.X[0].shape,e=this.input.Y[0].shape,n=this.attrs.axis;this.attrs.axis=-1==n?t.length-e.length:4-e.length-n}},{key:"flattenShape",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=t.find((function(t){return t.shape.length>2}));if(e){var n=U.padToFourDimShape(e.shape);e.shape=[n[0]*n[2],n[1]*n[3]]}}},{key:"reshape",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=t.find((function(t){return"origin"===t.tensorName})),n=t.find((function(t){return"counter"===t.tensorName})),i=t.find((function(t){return"out"===t.tensorName||"output"===t.tensorName}));if(n.shape.length>e.shape.length&&(S()("input"),e=n,S()("counter"),n=e),e.shape.length>2&&2===n.shape.length){var r=U.getReshapeInPaddle(e.shape,n.shape,i.shape);e.shape=r}}},{key:"mergeTensor",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],e=["scale","bias","variance","mean"],n={};t.forEach((function(t,e){n[t.tensorName]=t,n[t.tensorName+"Index"]=e}));for(var i=0;i<e.length;i++)t[n[e[i]+"Index"]].data=n[e[i]].data}},{key:"checkIsMerge",value:function(){return!!(this.name.indexOf("conv2d-elementwise_add")>-1&&Array.isArray(this.attrs))&&(this.name="conv2d_elementwise_add",!0)}},{key:"checkIsPass",value:function(){return"dropout"===this.name?"downgrade_in_infer"===this.attrs.dropout_implementation&&(this.name="scale",this.attrs.scale=this.attrs.dropout_prob,this.attrs.bias=0,!0):("depthwise_conv2d"===this.name&&(this.name="conv2d"),!0)}},{key:"dispose",value:function(){for(var t in this.input=null,this.output=null,this.attrs=null,this.tensor)this.tensor[t].dispose();this.tensor={}}}]),t}(),M=new A({}),k=M.getOpConfs(),W=function(){function t(e){r()(this,t),this.version="0.0.1",this.handler="io.IOHandler",this.weightMap="",this.options=e||{},this.feed=null,this.index=0,this.feedOp=null,this.feedItem=null,this.test=!1,this.formatLayout="NCHW",this.isExecuted=!1,this.iLayer=0,this.queryList=[],this.options&&this.options.options&&(!0===this.options.options.test&&(this.test=!0),this.options.options.formatLayout&&(this.formatLayout=this.options.options.formatLayout)),this.inst||(this.inst=new O(this.options.options),M.setWebglVersion(this.inst.getWebglVersion()),M.setIsFrameBufferSupportFloat(this.inst.getIsFrameBufferSupportFloat()),U.setTextureMaxSize(this.inst.getWebglMaxTextureSize()))}return a()(t,[{key:"buildOpData",value:function(t){var e=this,n=this.constructExecutor(t),i=new X(t.type,n.inputs,n.outputs,n.attrs),r=i.name;i.program=[],i.program=i.outputTensors.map((function(t,n){var o=M.buildShader(r,i.fShaderParams[n],n);return e.inst.createProgram(o,t)})),i.renderData=k[r].map((function(n){var r=Object.assign({},n),o=i.inputTensors.find((function(t){return t.name===r.tensor}));return"texture"===r.type?(r.tensorId=o.opts.type,r.data=o.data,e.feedOp.id===t.id&&"origin"===r.tensor&&(r.shape=o.shape,e.feedItem=r),r.width_texture=o.width_texture,r.height_texture=o.height_texture,r.channel=o.channel):"uniform"===r.type&&(r.data=o[r.variable]),r})),i.iLayer=this.iLayer++,t.opData=i}},{key:"execute_",value:function(t){if("fetch"!==t.type){var e=this.inst.gpu.gl,n=U.beginQuery(e);if(t.execute(this.inst,this.isExecuted),this.queryList.push({name:t.type,query:n,count:1}),n=U.endQuery(e,n),t.next){var i=t.next,r=this.getTensor(i);this.execute_(r[0])}}}},{key:"execute",value:function(t){this.feed=t;var e=this.getNetsStart(this.weightMap);return this.inst||(this.inst=O.init({width_raw_canvas:512,height_raw_canvas:512})),this.isExecuted&&this.updateFeed(),this.queryList=[],this.execute_(e[0]),this.isExecuted=!0,this.inst}},{key:"updateFeed",value:function(){this.feed.input&&this.feed.input[0]&&this.feed.input[0].data&&(this.feedItem.data=this.feed.input[0].data)}},{key:"predict",value:function(t,e){return this.execute_(t,!0,this.outputNodes)}},{key:"getTensorAttr",value:function(t){return this.data.vars.filter((function(e,n){if(t===e.name)return e}))}},{key:"constructExecutor",value:function(t){var e=this,n=t.inputsName[0],i=t.inputs,r=t.outputs;return Object.keys(r).forEach((function(t){r[t].forEach((function(n,i){r[t][i]=e.getTensorAttr(n)[0]}))})),Object.keys(i).forEach((function(r){if(!e.test||"Input"!==r&&"X"!==r)if("Input"===r&&"pixel"===n)i[r]=e.feed.input,e.feedOp=t;else if("Input"!==r||"image"!==n&&"x"!==n)if("X"===r&&i[r].length>1){var o=f()(i[r],3),a=o[0],s=o[1],u=o[2];i.X=e.getTensorAttr(a),s&&(i.Y=e.getTensorAttr(s)),u&&(i.Z=e.getTensorAttr(u),t.type+="_mul")}else i[r]=e.getTensorAttr(i[r][0]);else i[r]=e.feed.input,e.feedOp=t;else i[r]=e.getTensorAttr(i[r][0]),e.feedOp=t})),{inputs:i,outputs:r,attrs:t.attrs,type:t.type,next:t.next}}},{key:"constructOpsMap",value:function(t){var e=this;return t.map((function(n,i){var r=n.outputsName[0],o=e.getNextExecutor(t,r);return o.length>0&&(n.next=o[0].id),n}))}},{key:"arrangeMap",value:function(t){var e={},n=[],i={},r=t;return r.forEach((function(t,n){t.outputsName.forEach((function(t,n){e[t]=!0}))})),r.forEach((function(t,r){n[r]=0,i[t.id]=r,t.inputsName.length>1?t.inputsName.forEach((function(t,i){1==e[t]&&n[r]++})):n[r]=t.inputsName.length})),this.topoSort(t,n,i),t}},{key:"topoSort",value:function(t,e,n){var i=[];i.push(t[0]);for(var r=t.slice(0),o=null,a=t[0];i.length>0;){null!=o&&(t[n[o.id]].next=a.id),o=a,a=i.pop();for(var s=0;s<a.outputsName.length;s++)for(var u=0;u<r.length;u++)for(var _=0;_<r[u].inputsName.length;_++)if(r[u].inputsName[_]==a.outputsName[s]&&(e[n[r[u].id]]--,0==e[n[r[u].id]])){i.push(t[n[r[u].id]]),r.splice(u,1),u--;break}}}},{key:"getNetsStart",value:function(t){return t.filter((function(t){if("feed"===t.type)return!0}))}},{key:"getNetsEnd",value:function(t){return t.filter((function(t){if("fetch"===t.type)return!0}))}},{key:"getTensor",value:function(t){return this.weightMap.filter((function(e,n){if(t===e.id)return e}))}},{key:"formatWeight",value:function(t){"NHWC"===this.formatLayout&&t.map((function(t){t.data&&t.shape&&(t.data=U.nhwc2nchw(t.data,t.shape))}))}},{key:"createOpsMap",value:function(t){return t.map((function(t,e){return t.idx=e,new m(t)}))}},{key:"getNextExecutor",value:function(t,e){return t.filter((function(t,n){for(var i=0;i<t.inputsName.length;i++)if(e===t.inputsName[i])return!0}))}},{key:"dispose",value:function(){this.executor.dispose()}}]),t}(),B=function(){function t(e){r()(this,t),this.version="0.0.1",this.loader="",this.options=e,this.graph="",this.multipart=!1,this.feed=null,this.index=0,this.feedOp=null,this.feedItem=null,this.test=!1,this.isExecuted=!1,this.iLayer=0,this.params={type:"fetch"},this.environment=s}var e;return a()(t,[{key:"load",value:(e=l()(_.a.mark((function t(){var e;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:if(null!==this.options){t.next=2;break}throw new Error("modelGonfig in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");case 2:return e=new g(this.options.urlConf,this.options.options),t.next=5,e.load();case 5:return this.preGraph(e),t.abrupt("return",this);case 7:case"end":return t.stop()}}),t,this)}))),function(){return e.apply(this,arguments)})},{key:"preGraph",value:function(t){var e=new W(this.options);this.graph=e,this.graph.data=t.data,this.graph.formatWeight(this.graph.data.vars);var n=this.graph.createOpsMap(this.graph.data.ops),i=this.graph.constructOpsMap(n),r=this.graph.arrangeMap(i);this.graph.weightMap=r}},{key:"execute",value:function(t){var e=this;return this.feed=this.graph.feed=t,this.graph.isExecuted||this.graph.weightMap.forEach((function(t,n){var i=t.type;"feed"!==i&&"fetch"!==i&&e.graph.buildOpData(t)})),this.graph.execute(t),this.graph.inst}},{key:"updateFeed",value:function(){this.graph.feedItem.data=this.graph.feed.input[0].data}},{key:"dispose",value:function(){this.graph.dispose()}}]),t}(),V=n(6),j=n.n(V),Y=n(7),z=n.n(Y),Z=n(5),K=n.n(Z),Q=function(){function t(e){r()(this,t);var n=e.inputShape,i=e.outputShape,o=e.attrs;this.options=e,this.inputShape=n,this.outputShape=i,this.attrs=o,this.isEntry=!1,this.isLast=!1,this.inputTexture=null,this.outputTexture=null,this.inputTextureLoc=null,this.outputTextureLoc=null,this.program=null,this.pos={x:0,y:0}}return a()(t,[{key:"getFshaderSource",value:function(t){var e=t;if(this.attrs)for(var n=0,i=Object.keys(this.attrs);n<i.length;n++){var r=i[n],o=this.attrs[r];e=e.replace(r.toUpperCase(),o)}return e}},{key:"update",value:function(){}}]),t}();function q(t){var e=function(){if("undefined"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if("function"==typeof Proxy)return!0;try{return Date.prototype.toString.call(Reflect.construct(Date,[],(function(){}))),!0}catch(t){return!1}}();return function(){var n,i=K()(t);if(e){var r=K()(this).constructor;n=Reflect.construct(i,arguments,r)}else n=i.apply(this,arguments);return z()(this,n)}}function J(t){var e=function(){if("undefined"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if("function"==typeof Proxy)return!0;try{return Date.prototype.toString.call(Reflect.construct(Date,[],(function(){}))),!0}catch(t){return!1}}();return function(){var n,i=K()(t);if(e){var r=K()(this).constructor;n=Reflect.construct(i,arguments,r)}else n=i.apply(this,arguments);return z()(this,n)}}function $(t,e){var n;if("undefined"==typeof Symbol||null==t[Symbol.iterator]){if(Array.isArray(t)||(n=function(t,e){if(!t)return;if("string"==typeof t)return tt(t,e);var n=Object.prototype.toString.call(t).slice(8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return Array.from(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return tt(t,e)}(t))||e&&t&&"number"==typeof t.length){n&&(t=n);var i=0,r=function(){};return{s:r,n:function(){return i>=t.length?{done:!0}:{done:!1,value:t[i++]}},e:function(t){throw t},f:r}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var o,a=!0,s=!1;return{s:function(){n=t[Symbol.iterator]()},n:function(){var t=n.next();return a=t.done,t},e:function(t){s=!0,o=t},f:function(){try{a||null==n.return||n.return()}finally{if(s)throw o}}}}function tt(t,e){(null==e||e>t.length)&&(e=t.length);for(var n=0,i=new Array(e);n<e;n++)i[n]=t[n];return i}var et={resize:function(t){j()(n,t);var e=q(n);function n(t){var i;return r()(this,n),(i=e.call(this,t)).name="resize",i.needScale=!0,i.scale=[1,1],i.scaleLoc=null,i.fshaderSource=i.getFshaderSource("\n    #ifdef GL_ES\n        precision mediump float;\n    #endif\n    uniform sampler2D entry;\n    varying vec2 v_TexCoord;\n    void main() {\n        gl_FragColor = texture2D(entry, v_TexCoord);\n    }"),i}return a()(n,[{key:"update",value:function(t,e){this.resetPos(t,e)}},{key:"resetPos",value:function(t,e){var n=this.options,i=n.targetSize,r=n.scale;n.inputShape,n.outputShape;r&&i?this.resizeAndFitTargetSize(t,e):i?this.fitToTargetSize(t,e):this.resize(t,e)}},{key:"resizeAndFitTargetSize",value:function(t,e){var n=this.options,i=n.targetSize,r=n.scale,o=n.outputShape,a=f()(o,2),s=a[0],u=a[1],_=t,h=e;t<e?(_=r,h=Math.round(_*e/t)):(h=r,_=Math.round(h*t/e));var l=(_-i.width)/2,c=(h-i.height)/2;this.pos={x:l,y:c},this.scale=[_/s,h/u]}},{key:"fitToTargetSize",value:function(t,e){var n=this.options,i=n.targetSize,r=n.outputShape,o=i.width,a=i.height,s=f()(r,2),u=s[0],_=s[1],h=o,l=a,c=0,T=0;h/l*e/t>=1?(h=Math.round(l*t/e),c=Math.floor((o-h)/2)):(l=Math.round(h*e/t),T=Math.floor((a-l)/2)),this.options.center&&(this.pos={x:c,y:T}),this.scale=[h/u,l/_]}},{key:"resize",value:function(t,e){var n=this.options,i=n.scale,r=n.outputShape,o=f()(r,2),a=o[0],s=o[1],u=t,_=e;t<e?(u=i||t,_=Math.round(u*e/t)):t>e?(_=i||e,u=Math.round(_*t/e)):u=_=params.scale||t,this.scale=[u/a,_/s]}}]),n}(Q),format:function(t){j()(n,t);var e=J(n);function n(t){var i;return r()(this,n),(i=e.call(this,t)).name="format",i.normalizeAttrs(),i.fshaderSource=i.getFshaderSource("\n    #ifdef GL_ES\n        precision mediump float;\n    #endif\n    uniform sampler2D entry;\n    varying vec2 v_TexCoord;\n    const int width = WIDTH;\n    const vec4 mean = MEAN;\n    const vec4 std = STD;\n\n    float getData(vec4 color, int id) {\n        for (int i = 0; i < 3; i++) {\n            if (i == id) {\n                return (color[i] - mean[i]) / std[i];\n            }\n        }\n    }\n\n    void main() {\n        float outPadding = 1.0 / float(width) / 2.0;\n        float inWidth = float(width) / 3.0;\n        float inPadding = 1.0 / inWidth / 2.0;\n        float x = ceil((v_TexCoord.x + outPadding) * inWidth) / inWidth - inPadding;\n        vec4 color = texture2D(entry, vec2(x, v_TexCoord.y));\n\n        int channel = int(mod(v_TexCoord.x * float(width), 3.0));\n        gl_FragColor.r = getData(color, channel);\n    }"),i}return a()(n,[{key:"processMeanOrStd",value:function(t,e){var n=t;return t||(n="mean"===e?[0,0,0,0]:[1,1,1,1]),3===t.length&&n.push("mean"===e?0:1),"vec4(".concat(n.join(","),")")}},{key:"normalizeAttrs",value:function(){var t=this.attrs;t.mean=this.processMeanOrStd(t.mean,"mean"),t.std=this.processMeanOrStd(t.std,"std")}}]),n}(Q)},nt=function(){function t(e,n,i,o,a){r()(this,t),this.options=Object.assign({fill:[0,0,0,0]},a);var s=this.options,u=s.mean,_=s.std,h=s.shape;this.pipe=o,this.pipe.push({name:"format",options:{outputShape:h,attrs:{mean:u,std:_,width:3*h[0]}}}),this.gl=e,2===(this.glVersion=n)?(this.textureFloat=e.getExtension("EXT_color_buffer_float"),this.internalFormat=e.R16F,this.textureFormat=e.RED,this.downloadInternalFormat=e.RGBA16F):(this.internalFormat=e.RGBA,this.textureFormat=e.RGBA,this.downloadInternalFormat=e.RGBA,this.textureHalfFloat=e.getExtension("OES_texture_half_float")),this.frameBufferSupportFloat=i,this.initPipeLine()}var e;return a()(t,[{key:"initPipeLine",value:function(){var t=this,e=this.gl;this.framebuffer=e.createFramebuffer(),e.bindFramebuffer(e.FRAMEBUFFER,this.framebuffer);var n=this.pipe;if(n&&n.length){var i,r,o=n.length;this.pipeLine=n.map((function(e,n){var a,s=e.name,u=e.options;if(i=new et[s](u),0===n?(i.isEntry=!0,r=i):n===o-1&&(i.isLast=!0),i.inputShape=r.outputShape,t.initProgram(i),a=t.initTexture(i,i.outputShape),i.outputTexture=a.texture,i.outputTextureLoc=a.loc,i.isLast&&(t.outputTexture=i.outputTexture),i.isEntry)a=t.initTexture(i,i.inputShape||[]),i.inputTexture=a.texture,i.inputTextureLoc=a.loc;else{var _=r,h=_.inputTexture,l=_.inputTextureLoc;i.inputTexture=h,i.inputTextureLoc=l}return r=i,i}))}}},{key:"initShaders",value:function(t,e){var n=this.gl,i=this.createProgram(t,e);return i?(n.useProgram(i),n.program=i,i):(console.log("Failed to create program"),!1)}},{key:"createProgram",value:function(t,e){var n=this.gl,i=this.loadShader(n,n.VERTEX_SHADER,t),r=this.loadShader(n,n.FRAGMENT_SHADER,e);if(!i||!r)return null;var o=n.createProgram();return o?(n.attachShader(o,i),n.attachShader(o,r),n.linkProgram(o),o):null}},{key:"initProgram",value:function(t){var e=this.gl,n=this.initShaders("\n    attribute vec4 a_Position;\n    varying vec2 v_TexCoord;\n    uniform vec2 u_scale;\n    void main() {\n        gl_Position = a_Position * vec4(vec2(u_scale), 1, 1);\n        v_TexCoord.x = (a_Position.x + 1.0) / 2.0;\n        v_TexCoord.y = (a_Position.y + 1.0) / 2.0;\n    }",t.fshaderSource);if(n){t.program=n,this.initVertexBuffers(e);var i=t.scaleLocation=e.getUniformLocation(n,"u_scale");e.uniform2fv(i,[1,1]),e.clearColor(1,1,1,1)}else console.log("Failed to intialize shaders.")}},{key:"initVertexBuffers",value:function(t){var e=new Float32Array([-1,1,0,1,-1,-1,0,0,1,1,1,1,1,-1,1,0]),n=t.createBuffer();if(!n)return console.log("Failed to create the buffer object"),-1;t.bindBuffer(t.ARRAY_BUFFER,n),t.bufferData(t.ARRAY_BUFFER,e,t.STATIC_DRAW);var i=e.BYTES_PER_ELEMENT,r=t.getAttribLocation(t.program,"a_Position");if(r<0)return console.log("Failed to get the storage location of a_Position"),-1;t.vertexAttribPointer(r,2,t.FLOAT,!1,4*i,0),t.enableVertexAttribArray(r)}},{key:"initTexture",value:function(t,e){var n=this.gl,i=f()(e,2),r=i[0],o=void 0===r?1:r,a=i[1],s=void 0===a?1:a,u=n.createTexture();if(!u)return console.log("Failed to create the texture object"),!1;n.bindTexture(n.TEXTURE_2D,u),"format"===t.name&&t.isLast?n.texImage2D(n.TEXTURE_2D,0,this.downloadInternalFormat,3*o,s,0,n.RGBA,this.frameBufferSupportFloat?n.FLOAT:this.textureHalfFloat.HALF_FLOAT_OES,null):n.texImage2D(n.TEXTURE_2D,0,n.RGBA,o,s,0,n.RGBA,n.UNSIGNED_BYTE,null),n.texParameteri(n.TEXTURE_2D,n.TEXTURE_MAG_FILTER,n.NEAREST),n.texParameteri(n.TEXTURE_2D,n.TEXTURE_MIN_FILTER,n.NEAREST),n.texParameteri(n.TEXTURE_2D,n.TEXTURE_WRAP_S,n.CLAMP_TO_EDGE),n.texParameteri(n.TEXTURE_2D,n.TEXTURE_WRAP_T,n.CLAMP_TO_EDGE);var _=n.getUniformLocation(t.program,"entry");return n.bindTexture(n.TEXTURE_2D,null),{texture:u,loc:_}}},{key:"render",value:(e=l()(_.a.mark((function t(e){var n,i,r,o,a,s,u,h,l,c,T,p,E,d,I,g,m,x,v,H;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:n=e.input,i=e.width,r=e.height,o=this.gl,a=n instanceof Uint8Array||n instanceof Uint8ClampedArray||n instanceof Float32Array,s=this.pipeLine[0],u=s,h=$(this.pipeLine);try{for(h.s();!(l=h.n()).done;)c=l.value,u=c,T=c.program,p=c.inputTexture,E=c.inputTextureLoc,d=c.outputTexture,o.useProgram(T),this.program=T,u.update(i,r),o.bindTexture(o.TEXTURE_2D,d),I=f()(u.outputShape,2),g=I[0],m=I[1],this.attachFrameBuffer(d,[u.isLast?3*g:g,m],u.pos),c.isEntry?(u.inputShape=[i,r],o.bindTexture(o.TEXTURE_2D,p),o.activeTexture(o.TEXTURE0),o.uniform1i(E,0),1!==this.glVersion||a?o.texImage2D(o.TEXTURE_2D,0,o.RGBA,i,r,0,o.RGBA,o.UNSIGNED_BYTE,n):o.texImage2D(o.TEXTURE_2D,0,o.RGBA,o.RGBA,o.UNSIGNED_BYTE,n)):(x=s.outputTexture,o.bindTexture(o.TEXTURE_2D,x),o.activeTexture(o.TEXTURE0),v=o.getUniformLocation(T,"entry"),o.uniform1i(v,0)),u.needScale&&(H=o.getUniformLocation(T,"u_scale"),o.uniform2fv(H,u.scale)),o.drawArrays(o.TRIANGLE_STRIP,0,4)}catch(t){h.e(t)}finally{h.f()}case 7:case"end":return t.stop()}}),t,this)}))),function(t){return e.apply(this,arguments)})},{key:"read",value:function(){var t=this.gl;t.finish();var e=new Uint8Array(200704);t.readPixels(0,0,224,224,t.RGBA,t.UNSIGNED_BYTE,e),console.log("pixels==========="),console.log(JSON.stringify(e.slice(0,200)))}},{key:"attachFrameBuffer",value:function(t,e,n){var i=f()(e,2),r=i[0],o=i[1],a=this.gl;return a.framebufferTexture2D(a.FRAMEBUFFER,a.COLOR_ATTACHMENT0,a.TEXTURE_2D,t,0),a.viewport(0,0,r,o),a.scissor(0,0,r,o),this.frameBuffer}},{key:"loadShader",value:function(t,e,n){var i=t.createShader(e);if(null==i)return console.log("unable to create shader"),null;if(t.shaderSource(i,n),t.compileShader(i),!t.getShaderParameter(i,t.COMPILE_STATUS)){var r=t.getShaderInfoLog(i);return console.log("Failed to compile shader: "+r),t.deleteShader(i),null}return i}}]),t}(),it=(n(20),function(){function t(e){r()(this,t);this.modelConfig=Object.assign({inputType:"image",needPreheat:!0,usePipeLine:!0},e),this.flags={isRunning:!1,isPreheating:!1,runVideoPaused:!1},this.buffer=new Float32Array,this.io=new I,this.model=null,this.preheatFeed=null,this.utils=U,this.pipeLine=null,this.gpu=null}var e,n,i,o,s,u,h,c;return a()(t,[{key:"loadModel",value:(c=l()(_.a.mark((function t(){var e,n,i,r,o,a,s,u,h,l,c,f,T,p,E,d,I,g,m;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return e=this.modelConfig,n=e.inputType,i=e.fileCount,r=e.needPreheat,o=e.mean,a=void 0===o?[0,0,0]:o,s=e.std,u=void 0===s?[1,1,1]:s,h=e.feedShape,l=e.targetSize,c=e.scale,f=e.fill,T=e.usePipeLine,p=h.fw,E=h.fh,"/"!==(d=this.modelConfig.modelPath).charAt(d.length-1)&&(d+="/"),I={dir:0===d.indexOf("http")?d:"/".concat(d),main:"model.json"},g=new B({urlConf:I,options:{multipart:!0,dataType:"binary",options:{fileCount:i,getFileName:function(t){return"chunk_".concat(t,".dat")}},feedShape:h,mean:a,std:u,scale:c,targetSize:l,inputType:n,usePipeLine:T}}),t.next=8,g.load();case 8:if(this.model=t.sent,this.gpu=this.model.graph.inst.gpu,this.gl=this.gpu.gl,this.glVersion=this.gpu.version,m=this.gpu.frameBufferSupportFloat,T&&(this.pipeLine=new nt(this.gl,this.glVersion,m,[{name:"resize",options:{outputShape:[p,E],targetSize:l,scale:c}}],{mean:a,std:u,fill:f,shape:[p,E]})),r){t.next=16;break}return t.abrupt("return");case 16:return t.next=18,this.preheat();case 18:case"end":return t.stop()}}),t,this)}))),function(){return c.apply(this,arguments)})},{key:"checkModelLoaded",value:(h=l()(_.a.mark((function t(){return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:if(this.model){t.next=4;break}return console.info("It's better to preheat the model before running."),t.next=4,this.loadModel();case 4:case"end":return t.stop()}}),t,this)}))),function(){return h.apply(this,arguments)})},{key:"preheat",value:(u=l()(_.a.mark((function t(){var e,n,i,r,o,a,s;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return t.next=2,this.checkModelLoaded();case 2:return this.flags.isPreheating=!0,e=this.modelConfig,n=e.feedShape,i=e.usePipeLine,r=n.fh,o=n.fw,a=this.preheatFeed=[{data:new Float32Array(3*r*o).fill(5),name:i?"feed":"image",shape:[1,3,r,o]}],s=this.model.execute({input:a}),t.next=9,this.runAfter(s);case 9:return this.flags.isPreheating=!1,t.abrupt("return",this);case 11:case"end":return t.stop()}}),t,this)}))),function(){return u.apply(this,arguments)})},{key:"run",value:(s=l()(_.a.mark((function t(e,n){var i,r,o,a,s,u,h,l,c,f,T,p,E,d,I,g,m;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:this.flags.isRunning=!0,i=this.modelConfig,r=i.feedShape,o=i.fill,a=i.targetSize,s=i.scale,u=i.mean,h=void 0===u?[0,0,0]:u,l=i.std,c=void 0===l?[1,1,1]:l,f=i.usePipeLine,T=i.inputType||"image",p=r.fh,E=r.fw,I=e.data,g=e.width,m=e.height,f&&("[object HTMLImageElement]"===Object.prototype.toString.call(e)?T="htmlImageElement":"[object ImageData]"===Object.prototype.toString.call(e)?T="ImageData":e.data&&(e.data instanceof Uint8Array||e.data instanceof Uint8ClampedArray||e.data instanceof Float32Array||e.data instanceof ArrayBuffer)&&(T="arraybuffer")),t.t0=T,t.next="video"===t.t0?10:"image"===t.t0?12:"htmlImageElement"===t.t0?14:"imageData"===t.t0?18:"arraybuffer"===t.t0?23:28;break;case 10:return d=[{data:e,shape:[1,3,p,E],name:"image"}],t.abrupt("break",29);case 12:return d=this.io.process({input:e,params:{gapFillWith:o||"#000",targetSize:a,scale:s,targetShape:[1,3,p,E],mean:h,std:c}}),t.abrupt("break",29);case 14:return m=e.naturalHeight,g=e.naturalWidth,d=[{data:{width:g,height:m,input:e},width:g,height:m,outShape:[1,3,p,E],shape:[1,4,m,g],name:"feed"}],t.abrupt("break",29);case 18:if(g&&m&&e){t.next=21;break}return console.log("imageData类型的数据，需要传ImageData类型数据"),t.abrupt("break",29);case 21:return d=[{data:{width:g,height:m,input:e},width:g,height:m,outShape:[1,3,p,E],shape:[1,4,m,g],name:"feed"}],t.abrupt("break",29);case 23:if(g&&m&&e){t.next=26;break}return console.log("arraybuffer类型的数据，需要传data，跟img对应的宽高"),t.abrupt("break",29);case 26:return d=[{data:{width:g,height:m,input:new Uint8Array(I)},width:g,height:m,outShape:[1,3,p,E],shape:[1,4,m,g],name:"feed"}],t.abrupt("break",29);case 28:return t.abrupt("break",29);case 29:return f&&(this.pipeLine.render(d[0].data),this.model.graph.inst.gpu.texturesMap.image=this.pipeLine.outputTexture,d=null),t.next=32,this.runWithFeed(d,n);case 32:case"end":return t.stop()}}),t,this)}))),function(t,e){return s.apply(this,arguments)})},{key:"runAfter",value:(o=l()(_.a.mark((function t(e){var n,i,r,o,a,s,u,h;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return t.next=2,e.read();case 2:return n=t.sent,i=this.modelConfig.fetchShape,r=i[0],o=i[1],a=i[2],s=i[3],u=[r,a,s,o],h=U.nhwc2nchw(n,u),U.stridePrint(h),U.continuousPrint(h),t.abrupt("return",h);case 13:case"end":return t.stop()}}),t,this)}))),function(t){return o.apply(this,arguments)})},{key:"runWithFeed",value:(i=l()(_.a.mark((function t(e,n){var i,r;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return t.next=2,this.checkModelLoaded();case 2:return i=this.model.execute({input:e}),t.next=5,this.runAfter(i);case 5:return r=t.sent,t.next=8,n;case 8:if(t.t0=t.sent,!t.t0){t.next=11;break}n(r);case 11:this.flags.isRunning=!1;case 12:case"end":return t.stop()}}),t,this)}))),function(t,e){return i.apply(this,arguments)})},{key:"runStream",value:(n=l()(_.a.mark((function t(e,n){var i,r=this;return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return t.next=2,this.run(e,n);case 2:return i=t.sent,"video"!==this.modelConfig.inputType||this.flags.runVideoPaused||setTimeout(l()(_.a.mark((function t(){return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return t.next=2,r.runStream(e,n);case 2:case"end":return t.stop()}}),t)}))),0),t.abrupt("return",i);case 5:case"end":return t.stop()}}),t,this)}))),function(t,e){return n.apply(this,arguments)})},{key:"stopStream",value:function(){this.flags.runVideoPaused=!0}},{key:"predict",value:(e=l()(_.a.mark((function t(e,n){return _.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:if(this.flags.runVideoPaused=!1,"function"!=typeof e){t.next=6;break}return t.next=4,this.runStream(e(),n);case 4:t.next=8;break;case 6:return t.next=8,this.runStream(e,n);case 8:case"end":return t.stop()}}),t,this)}))),function(t,n){return e.apply(this,arguments)})}]),t}());s.env().canvas&&(window.Paddlejs=it);e.default={environment:s,runner:it}}]).default}));